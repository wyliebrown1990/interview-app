 1.0.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5 Hello and welcome to the observability trends webinar series. I'm Grant Swanson your host and today we will explore the topic of scaling observability, managing petabyte volumes of data in real time. We will start with a short overview presentation that highlights our unique architecture. Followed by a live product demo, everybody on the webinar will receive an email with a link to the webinar recording shortly after the session. For those interested, we will be conducting a DevOps and SRE observability workshop on February 8, where attendees can get hands-on technical training on how to use log explorer, trace explorer and metrics explorer to troubleshoot real-life scenarios. We will be doing the registration page available in the chat window. Now I would like to introduce our guest speaker, Principal Solutions Engineer, Matt Ray. Welcome Matt. Thanks Grant. Let's go ahead and hop in here. The first thing that we want to talk about with the observability is the architecture. This is what ultimately allows us to manage these hundreds of petabytes of petabytes scale range amounts of data. While still being able to provide a good user experience to the end users that are coming in and querying and working with the data. Our approach can really be broken down into a few different parts. The first part is that we're built on a data lake. The whole idea behind this is that we can take data from any source within your environment, whether that be your cloud environment, your Kubernetes, open telemetry from a tracing perspective, as well as business-level data, things like your GitHub commits and your tickets coming in from a Zendask. We take all of this data and put it into one common data lake. From there, we store everything on it, compressed and decompressed on the fly by default for 13 months. Once that data is in the data lake, we start to build out the schema and the relationships within that data and what we refer to as the data graph. What this is doing is applying schema and structure to the data that you've sent into the data lake and allowing us to link and correlate related entities within the information so that as your troubleshooting, you have the ability to automatically understand and move across the related entities and resources without needing to switch screens, switch tools, or manually try to stitch together information. The last piece to our architecture is really these data applications. All of these are out of the box content that helps to get you up and running quickly. Things like dashboards, alerts, data sets, that have a predefined understanding of common entities like AWS, Kubernetes, so on and so forth, so that you can get up and going and don't have to worry about manually creating or building out this data. You can really focus on getting started quickly. From there, there's really two areas that I think are important to dig deeper into, especially when we're talking about how do we manage large scale and large volumes of data. So the first one is on the less the city side. Really, the reason that we're able to do this is because observe has utilized this data lake concept in order to separate storage and compute and be able to provide high performance of both. So if we think about the way that a traditional monitoring tool is built out, there's these concepts of hot storage and warm storage and cold storage. And then if your data is too old, it has to be dehydrated and brought back into hot storage so that you can query it. And what we see for our customers is a that creates a lot of time and effort needed in order to troubleshoot, but it also can be complex and determining how much do we retain and where do we retain it. So observe stores everything in cloud storage. It's always hot and compressed and decompressed on the fly. So there's no need to worry about what data is living within what tier. And you can always go through and query any of the data within the system. The other piece is that we've separated out the storage from the compute. And what that means is that rather than going and defining a static amount of compute based on what your average load is or what you're expected high load is. Having to worry about the performance of the system when you go to run a large query, we've actually created a multi tenant data warehouse architecture utilizing snowflake where we understand the queries that you're running and the amount of data that you're processing and then assign an amount of compute, and then compute relevant to that query and what you're processing in order to deliver high performance to you. And so what that means is that when you're using the system heavily, you get a lot of compute and high performance. And when you're not using the system heavily, you aren't burning money and having compute standing there running that nobody is taking advantage of. And so it ends up providing a much more economical way to manage and utilize high volumes of data without breaking the bank from from a budget perspective. And so going into that a little bit more, the way that that compute scheduling works is we have a scheduler. And it'll understand what is the query that's being around. So if you're running a bunch of small queries, say loading up a dashboard, well, we can spread a lot of small queries over a lot of small compute instances in order to load that dashboard quickly. So if you're running a large query, over say a long time period, well, then we can utilize large compute instances and split out the query across multiple instances in order to process large amounts of data in an efficient amount of time. That's really where that underlying data lake architecture helps us to be able to match the processing power of the system with the questions that you're trying to answer so that we can drive performance, even when you're looking over large quality data. Now the other piece that plays into the performance of the overall system and being able to manage very large amounts of data is this concept of acceleration. And what we mean by that is basically taking an understanding the data coming in so that you can query it faster on the back end. If we look at the architecture, one of the paths that we've been talking about is at how queries, what am I going to query right now, what am I looking at, and those run directly through the scheduler in order to determine what is the best amount of compute. But for transforms that are run on a consistent basis say I always want my container logs to have a certain set of fields associated with them. We can batch and transform those so that when somebody comes in and needs to troubleshoot, they're always available and quick to query. So really the way that we can think of this is as a path where we have some observations coming in and as we move down the path, we do these transforms or accelerations where we're materializing out the data that is relevant to us. And as we move further, further down the data becomes more specific faster and query. So we'll go into that a little bit more in the demo, but that's a high level overview of the concepts of elasticity and acceleration that are helping us to drive high levels of performance for our customers. And with that, let's go ahead and hop over to the demo. Okay, so here we are in observe and the first thing that I want to do is just pop down to the data streams. And in this environment, you can see that I have a few different things coming in here. So I have my AWS data. I have some physical hopes that I'm monitoring Kubernetes. I'm bringing in open telemetry. I also have things like my GitHub logs and Zendesk data that's all coming into this data lake. Again, without me needing to apply a structure or necessarily understand the format that the data is coming in before it gets here. Once we have the data coming into the data lake, we can go and look at it. And if I hop into this this Kubernetes data stream here, you'll see that the raw data that we have coming in is fairly basic, right? It's basically just a JSON blog that we're getting out of our Kubernetes logs along with some extra metadata type of information. But as we go through that process of acceleration, we start to build out the things that we care about and want to look at from a Kubernetes perspective. So if I come in zoom in here, you can see that there's a few different things that we're building out of Kubernetes, things like API updates and it's shaped container logs. And as I come into any one of these nodes along the acceleration path, I see that as we move forward, we get more and more specific with the types of resources and the types of entities that we're looking at. And so this becomes really powerful as we're talking about looking through large amounts of data to where I can go and query container logs to go into in a minute and have a good set of information. But then I can also understand how a container log transfers to an app log for a specific type of container. And I can start to build resources for things that I want to look at within the data. So things like my users and my manufacturers associated with the data in order to give me a point of view for troubleshooting that's defined by a resource or a thing I want to ask questions about versus just searching through raw events and raw logs with that. Let's go ahead and hop into the log explorer for those container logs that we were looking at earlier. Now the log explorer is really designed to be a first stop place for being able to go and explore your data and understand what's going on. So you can see here that I have a number of log data sets within my environment. I've chosen the Kubernetes log right now. I also have a number of filters that I can easily come and click through and choose a filter that updates my search bar on top. And it also changes the context of the logs that I'm looking at over here. And with these container logs, we can see that they started to be shaped into things that we care about. So we still have a log line message that's based on the log coming out of the container. But we've also started to build out an understanding of things like containers, pods and clusters that are relevant to to Kubernetes logs that we would want to look into. So with this, right, we can see that there is some relevant data, but there's maybe more that we want to do in this log. I see that there's quite a bit of information stored within the actual line here. So one of the things that I can do is I can double click and start to grab data that's relevant to me and extract them out of fields. So maybe I'll grab the span ID, the trace ID, and the level for right now. As I pull those fields out, I'm then able to immediately see these columns directly within my log search here. We refer to this as schema on demand. It gives me the ability to without necessarily knowing what I want to ask about as I'm creating the data set. To come and on demand to find what are the things that I want to search on? What are the things that I want to filter on? So as an example here, we just pulled out this level. One of the things I can do is I can come back and say maybe instead of 15 minutes, I want to look at four hours of performance history. So I'll come back and do four hours. And then I can come to this level and say, let's go ahead and filter this. And instead of looking at everything, I just want to see the air logs over the last four hours. And immediately search over the fields that I've just added into the log data set here. And so now I'm pulling in only the errors associated with this app server. And I didn't have to do anything extra to build or maintain a new schema coming in. But if I'm going to be in here looking at this app server, right, extracting these fields all the time, that might be something that I do want to come out and say accelerate, right, have this available as a data set for any user that wants to come in and utilize the system. And so from that, all I would do is come up and save the data set and publish it as a new log data set. And that's essentially what we've done here with these application logs. So you can see that we have the same message and level that we were looking at earlier, along with that stack trace that you saw. And the relevant information about things like the container, the pod cluster. And we've also pulled in some other pieces of data things like our span and trace and user session. The way we've done this is utilizing our graph link, which is essentially a sequel join across primary foreign key pairs. So now I've tied the trace that is coming out of my Kubernetes logs with the trace that's coming out of OPEL. So I can easily make connections between those two points. And so if I come in here to say trace, I can add related fields. And maybe into this container log data set, I want to pull in things like the duration to this data set. So I can easily not just pull in information that's relevant or extracted from the logs that I'm looking at here, but actually create relationships across data sets and pull in relevant information. As I need it, as I'm investigating issues within within my environment. And then just like we did earlier, we could always come through and sort by or filter this associated information. And so that's really the power that observe offers, right, is the ability to to go through and understand and work with your data without needing to worry about having that pre applied schema or maintaining an index. You can easily leverage the power of the data warehouse in order to pull in and build on demand, what you're looking at and create links between data that traditionally people have had to link via engineers remembering timestamps and UU IDs as they move across different tools. And so that's really how we enable our customers to leverage and utilize large amounts of data. Now, some of the other pieces here, we can always come through and further dive into those links. So for instance, we have the screen link here on pod. If I go and click this, our graph link allows us to now see all of the data that's relevant to this pod, things like the namespace and cluster, but we can also get the IP address and the status of the overall pod. We can also hop over to the metrics and similar to the way that we were looking at the log data, we can immediately see all of the metrics that are relevant to this pod. And if I wanted to, I could jump over and move from my log explorer to my metric explorer to understand what's going on with, with the in this case garbage collection size for this pod. I can also back out and say, maybe I don't want to look at just this pod, but maybe I want to look at all the pods. And I can even add cardinality by coming in here and saying, let's also get an understanding of which cluster they're living in and which namespace and start to build out these really high cardinality type of use cases where we have multiple points all leveraging the data warehouse behind observe and the ability to utilize the SQL joins. And so what we see with our customers is that this becomes really impactful because now we can do things like tie metrics to individual transactions or individual customers or user sessions. There's really high cardinality type of use cases that you're not necessarily able to to obtain with other tools. So that's just a brief dive into some of the metric side of the world as well. But to wrap things up, what I want to do is actually hop back over to the log explorer and take a look at these container logs. So I know we're really supposed to be talking about scale during during this webinar. And a lot of the pieces that we've touched on, right, the elasticity, the acceleration, the ability to build relationships on demand, given the architecture that observe is built on, are really the underlying or underpinning things that allow us to manage these really high volumes data. But just to bring that to life, one of the things that we can do is we can come back and say, what's instead of looking at the last 15 minutes, jump back, maybe a few months and go ahead and apply that. Now we're looking at our container logs across a few billion points of data that we have loaded up in here. So one use case that I was working on with a customer recently was understanding all of the hits they've had on a particular IP address across a large period of time. And so one of the things that I can do is just come in here and say, I'm going to search the logs for anything that contains this particular IP address and port. And go ahead and run this query. And what we'll see is that within a matter of a couple seconds, right, we're able to query across billions of lines and bring back millions of results, all utilizing that the power of the data warehouse that that we have running behind the scenes. And so that concludes everything that I was hoping to show today.