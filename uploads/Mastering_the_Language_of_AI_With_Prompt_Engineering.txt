 Hello from Sydney and welcome to the Proof of Concept Podcast. The tech show where we explore real life use cases from the field and discuss those hot questions in the field of data science and AI. I am your host Grant Case, RVP for Sales Engineering here at DataIQ and APJ. And here on season three of the Proof of Concept Podcast, we've had our eye on 2026. Funny, it's a little over two years away and we're about half way through the 20s and they'll be over. To get ready, we've focused this season on what you can learn, understand and experience in order to get best prepared for the coming changes in the marketplace, whether you're just starting your career or you're a season executive. Today's episode, we're going to focus on that thing that's in everyone's LinkedIn feed right now and that's prompt engineering. And to do that, my guest today is a gentleman who has definitely found space in my LinkedIn feed and it should yours as well. Today's guest is Jepsen Taylor. Jepsen is the chief AI strategist here at DataIQ and here to help me understand and chat about that future of AI and how prompt engineering is in the middle of it. So welcome to the podcast, Jepsen. Thanks, Grant. I'm excited about this topic. It's changing every day. You're not lying and it seems like every day it's changing here when we're talking about LLMs, prompt engineering, all of that could stuff. So let's kind of dive into it and drop it in our ABCDE format and we'll start with the A, the abstract. So Jepsen talk a little bit as what is all of this prompt engineering about? So prompt engineering, it's constructing inputs into generative. So generative AI, you have chat, GPT that kind of really brought this into the world where people were shocked at its capabilities. So prompt engineering is crafting inputs into these LLMs that will produce better outputs. So think of a novice beginner versus someone who's very advanced in what they might be able to produce and what we see on the far spectrum from the expert side, some of the things that people can produce are shocking, unbelievably shocking. The amount of work they can do, the documents they can write. Yeah, so happy to dive into it. Yeah. So and again, I think for me, this is one of the interesting things about all of this prompt engineering is in effect, the idea and concept I can ask questions and prompt engineering to me is all about asking questions and trying to get that response. And ultimately the how well you formulate the question has been something that is very much indicative of how good of an answer you get out and prompt engineering is nothing more than that. Is that a fair statement? Yeah, that's a fair statement. I think a big thing is a big thing that surprises people is sometimes it's all about the context, right? So you and I could ask a simple question and it might produce very different responses because there's some randomness to it. And for some of the best prompt engineers, the questions that are asked are quite long. There's a lot of context that's given style outcomes. What you're really trying to anticipate is you don't want to go through constructive criticism cycles or iterations because you could imagine if you asked a very simple question or one liner, it might produce something that's not quite right and you could give it feedback, give it feedback. And so really good prompt engineering is trying to get ahead of that. Okay, interesting. So let's break it down a little bit. So how do when you as the chief AI strategist here at DataIQ, you're in these executive meetings all across the world. Someone who probably puts a lot more miles on whatever airline you like to fly than I do. So when you're talking to executive CEOs, chief data officers, what are you talking to them about when it comes to prompt engineering? So my favorite thing, Grant, is to do live demos because that's where the jaws to drop. That's where people are completely shocked at what you're able to do. One of the things I want to sneak in for the audience very quickly is we've already had prompt engineering before, but it's been very light. So someone being good at Googling. So you might have someone who's been Googling for a very long time. They can extract information and knowledge from the web much faster and more efficient than someone who hasn't used that before. And so I would argue based on our age, you and I are pretty good Googlers, but I don't think most people would see that as a major differentiator on getting a job. Prompt engineering is very different. So the thing I like to show people is I, I'm a big fan of pushing people. And what I mean by that is I like to raise the alarm that this is moving much faster than they realize. And so to casually wait until tools show up on their doorstep, that is the wrong mindset for this. And so the things all often do when I'm presenting to executives is I'll ask what their priorities are. What do you have priorities in product right now, priorities in marketing, sales, what are some of the executive functions that you do. And so I have a lot of fun showing them, let's build a marketing campaign right now, or let's engineer a new feature that your engineers might consider. Or how might I go after crafting an expert sales outreach message to an executive? Could I consume everything they've said publicly in the news and then have something that's on point? And so I have a lot of fun doing that because you can, you, you see the, the look in executive faces where they realize they need to do something. And I think right now that is absolutely something that every, every organization I'm talking to right now wants to talk about this concept of idea of generative AI. And really for me, the nexus of a lot of this is the prompt engineering itself. It is the secret sauce. But one of the things I'm hearing a lot about and I'm curious to hear your feedback is kind of two, two concepts that are happening right now. Number one is the first is, well, is prompt engineering just going to become another programming language? Are we going to run into the, are we, are we creating a priesthood of prompt engineers that is ultimately going to be the ones who can talk to the LLMS? What's your response to that? I'll lean into that. And I'm going to say something that's completely against it. And it's not my opinion is something else I heard. And I'd love to get your take on this. So to lean into that for expert prompt engineers, for, for people that are really, really good, where their experts at their domain, let's take a senior principal of engineer and they've obsessed over prompt engineering. I think you're looking at a scenario where that individual can do 10 times the work. Like it's, it's shocking. The amount of work that they can do compared to what they could do before is unbelievable. The amount of code they can write, the unit tests, and they're not just producing massive amounts of garbage. They're not producing thousands and thousands of lines of source code. They're producing high quality code with unit tests very well documented. And we see examples too where I see examples where they can write code that is very tedious code that they might lack the patience to work on. And so I think what you see is English has become the new programming language. There's also people talking about you might have people gravitating to a single programming language, think of pseudo code. So if you enjoy writing Python scripts or whatever the master language becomes, just write all your code in Python scripts. And then you can ask for translation. So if you want to translate it into whatever the languages of the day. Julie. Maybe. For instance, well, I love that you said Julia because I was going to throw that into the mix, but I was, I was, I was held back a little bit thinking that maybe that might be too technical. But since you said it, we're going to lean into Julia. So Julia showed up 10 years ago. It was a while ago. And there was a lot of hype when it showed up because just in time compiling, it can run just as fast as C. It was very friendly like Matt Lab or Python. But then like people like me that rolled up their sleeves and said, I love Julia. I'm going to give it a try. It was missing all the libraries. Like nothing was written for it. But now thanks to cheap T4 and these new generative AI technologies, you're, if Julia is the winner, you can start writing all the libraries. That's not a big deal. And so, so I love the idea of engineers being able to trans. I wrote a 410 490 script. Terrible. Like if I had to learn that and write it, it was awful. But GPT4 wrote it and it compiled. And again, I think that's one of the keys. I'm a big fan of Douglas Adams, Hitchhiker's Guide in the Battlefish. I know we started out for many of us. We had the altivista, battlefish, altivista. We had Google Translate. But we never had that for the languages themselves. And I know a lot of organizations today are, they're still running up against I have SAS code or or even I have GCL or older languages still sitting out there. But they can never move it because they don't have either the time, willingness or knowledge to do that. I see a lot of the prompt engineering to help with that being able to ask the questions to actually get it the response I need. Well, you're hitting on a very profound topic and that is you have a bunch of archaic systems that run everything. So like trading systems like you go into these bigger banks or these other organizations, you're standing on the shoulders of dinosaurs. Like literally dinosaurs, everything's written cobalt. It's written in old languages that are not well known. And for you to translate an update, that's no longer going to be a very, very large multimillion dollar task. It'll be something you and I could roll up our sleeves and say time to translate cobalt as long as I have these scripts available. So it's so maybe systems will stop breaking. Maybe, but that may be put us out of a job, but that's okay. Well, I see this as being very prohuman. I did want to throw something in that's a little bit provocative based on the earlier question you had about prompt engineering because you could you could see the 10x engineer or maybe even the theoretical 100x engineer if you start building tools on top of tools and building apps based on requests, you're going to see that stuff show up. Someone I heard someone say a couple a couple weeks ago, if not a few months ago, that prompt engineering will be gone within a year. And what which leads me to my second question is, is this is prompt engineering just something that's going to be a flash in the plan? I just read an article from Professor Akkar, Kings College in London in the Harvard Business Review East, like all of this stuff, it's all going to go away. It's more problem formulation than necessarily writing very robust and esoteric prompts to get things happen because the AI is going to be there to actually do it for us. I think you'll see a trend, whether or not it will completely go away. That's to be determined. But you're definitely going to see a trend moving in the right direction. So if we had someone join this meeting with us and let's say it's a CEO, they tell us about their company, and then we we ask them to generate a marketing campaign in front of us using GPT-4. It's not going to be as good as you have data IQ. We've got some great marketing folks. We've got some great engineers. If they were all in the room working together, they're going to be able to build a fantastic marketing campaign. Not just one. They'll have multiple ones that are being scored, they're being prioritized, images are being built. And so that complicated deep knowledge within technical marketing will just be thrown into a generative AI pipeline. So today, you and I might bet on the technical team at Data IQ, great marketers, great engineers in a room working together. But in the future, that CEO should be able to just make a request, this is my company. And I want some competitive marketing campaigns. And this goes back to the very start of this conversation. Really good prompt engineering is anticipating feedback. So if you throw that into the mix right now, that CEO will be disappointed. They'll say this marketing campaign feels very pitchy. It feels like 2010 all over again. And they'll throw all these things in. And the experts that we mentioned would not, they would anticipate that. Excellent. And we'd love to hear back from you guys. What do you think about prompt engineering? Is this the future? Is this something that you're starting to work on yourself right now? Please drop us comment here on YouTube, LinkedIn, or anywhere where you're getting your podcasts. So let's kind of compare and contrast this, Ben and our Jepson. Sorry. One of the keys for us has been in this discussion. And we kind of alluded to it earlier. What's the difference really between something like what we were talking about Google versus what the prompt engineer is? Well, any other question formulation, really. So this is a really big question that you're bringing up because the contrast is it's a step function change. So the analogy I'll give is when I use Google today, it feels like I'm going back in time to 2001, which is fascinating because I don't think you and I would have complained about Google nine months ago. That's great. I have a bug. I throw it in. I go hunting. I read enough stack overflow and eventually I might find the solution. But let's be honest, it might take a few hours. Now with generative AI, it's like surgery for knowledge. You're going right to the specific thing that you could have found. The internet, I tend to be a little bit more emotional when I start to compare things. And so now when I think of the old way of doing it, it feels like I'm going to the knowledge landfill. You go look at the blog. This blog is garbage. You look at another blog. It's the wrong version, wrong system, no longer a principle. This screen is just somebody trying to game the Google system to get clicks. Well, in some of that, you're bringing up another really good point. Some of that, the it's not aligned with your knowledge retrieval or access. So oftentimes when you're clicking through to get something, there is a paid incentive. The perfect example is go and type something into Google images. A lot of the images you're being shown have watermarks. That's not what you wanted. But that's what Google's being paid for. Because when you click into those image services, you're more likely to pay and they'll get some fraction of that. And so there's, it's fast. I'm fascinated by the disruption in the market. If you were, if you were an image hosting service, how do you compete against the mid-journey solutions, those generative image solutions when I have humans with hands? Yeah, a lot of the a lot of the issues are getting fixed, like some of the artifacts are quickly going away. I think it's going to be harder and harder to know the difference. And I think for me on when I try to think about just this compare and contrast with, and let's continue to use Google. So when we think about the prompt engineering, Google has always tried to infer context. So if I'm asking a question here in Australia, they're going to try to put the Australian slant on it, whereas if I'm, so if I tell me or find me the site catch catch.com.au is a very used site here, but I would never really be prompted with that in the US. It's really the context for me. And being able to really use the input data, so giving the boundaries and constraints on what, instead of having to do dash site, you know, colon, whatever site to ignore or plus this site, stack overflow. Yeah, the contact, the ability to add the context and the parameters and contrast becomes to me is what makes this leaps and bounds ahead of anything else I've seen up to this point. Well, in the example you brought up, that is expert expert level Google search engine. Like most people do not go to that level, but also what you're bringing up, it feels very robotic, very mechanical, doesn't feel very human. But GPT-4, on the other hand, feels totally human. You don't have to, like Alexa, you don't have to say commands the exact way that you intended. You don't have to put in the Google chains the exact way that you had to before. You can just have a very human conversation. And I think that to me is one of the keys when we start to compare and contrast the prompting is, ends up being, I'm writing another episode right now, and I can have a conversation back and forth and it's very natural. And that naturalness is what's really kind of to me is what the value is in a lot of ways. And kind of dovetails us nicely into kind of our next next set of discussion point is when we think about what this does and what prompt engineering does, the value, how do I make money, save money, improve the customer experience when it comes to prompt engineering and these generative AI, and I think the sky is the limit. To me, it becomes the value is in, almost for me, it's the ability to kind of go back and forth with it. It's like having a conversation. The prompting is like having a conversation with another colleague who, or a mentor that knows a lot more and can kind of help guide my discussion in the life process. It is exactly that, but it's also having a conversation with another employee that has more experience than any employee you've ever interacted with. So I absolutely. So if I think about some of the most seasoned engineers, so think of like Super DevOps, Principal Level Engineers, if you have a gritty, difficult programming question, or if you want to do something impossible in Bash, you go to have them on the shoulder and they'll show you how to do it most of the time. But now, because of GPT-4, you can roll Apple script into Bash commands. You can do all these things that there's no single human on the planet that has done all those things. And so that I am very excited to see where this goes because it's not, yes, it's great to make people who aren't expert users of that able to leverage those tools, but I'm much more interested to see what are the great people do. So what is the expert that was already an expert? What do they do? And that's also true designers. For the really good designers that I interact with, they're celebrating this. They're not concerned. They're able to do projects that they lacked the resources to pull off or they lacked the time to pull off because it would have taken them weeks. And for sometimes with the design projects, the fine tuning can be very frustrating. If you're doing a big design project, trying to get this just right. And so I see this as a catalyst. We can all move faster. And I think to be that becomes one of the, in addition to kind of the naturalists and the ability to interact through prompt engineering. Like you said, prompt engineering is automation. I think it's, I forget the auto GPT. So creating bots that help create the AI to answer the questions, but it's doing it in the background and you don't even have to do it. To me, that's insane. If you don't have, you know, you talked to me about that even a year ago. Yeah. It's really interesting the unit of work that is showing up because for humans, we, a business has made up a people in process and we typically work those processes every day. That's a job. And the unit of work that we're beginning to bring to the table. So think of robotic process automation. Like there, if you download this file, if you do these three things, four or five things, that was already available to you to bring into the automation pipelines. But because of these new technologies, you, you're much more likely to be able to consume massive amounts of text or code in a way that is, is useful. I think if you were doing that before that, hey, we want to use natural language processing from the year 2010 and we're going to use it to prioritize legal docs. That sounds very brittle. It just, it sounds, it sounds like more work than it's worth. But today, it, it sounds game changing. Absolutely. Absolutely. And for those who have an interest in this kind of this concept, John Blick, who was with us last season talking about, kind of taking your own kind of consciousness and the digital twin, that's a great podcast. And is very relevant to this conversation when we're talking about LLNs. And of course, anything, what do you think in terms of deliverables? Please drop us a comment, fight us on Spotify, LinkedIn, YouTube, and anywhere else you might get us. We'd love to hear your comments as well. So that takes us kind of to the end, Jepsen and to the evolution part of the conversation. So I'd like you to put on your prognosticators cap. Where does prompt engineering go from here? It's a new frontier. So the analogy I'll use is imagine, imagine humans around the campfire. And this is the campfire of knowledge. We, you feel safe. You can go over to this region, the camp over that region, the camp. And if you go beyond that, you have new, new novel discovery. So this could be scientific breakthroughs, code breakthroughs, creative breakthroughs. And so, where we go from here, I think on all fronts, you're going to have humans doing things that humans didn't know they could do. And so we see examples today. We see generative AI art that I would argue humans can't do within a timeline and budget. And in me lagging to say, less than $1,000 one week, there's generative AI art that humans cannot do. And then that will also be true of code. There will be code that humans can't write. It's so incredibly tedious. It's so incredibly complicated. It's so the guarantee of failure with a human writing it is almost absolute, like almost 100%. So I'm really interested to see, but also the cleanup, I think the last thought I'll throw into this. I'm an optimist, I think very good things are going to happen with this. And I think today you have a lot of humans that are spending time keeping legacy, his systems running, processes, stale processes working tomorrow. And I'm really excited for a lot of that to become automated. So a lot of these people are evolving process, working on new process, new innovation. I think there's a level of urgency for the work that's coming out of generative AI to end up in healthcare. After COVID, I think it's really raised awareness around our lack of data literacy with healthcare data. We never leveraged the full strength of the global data when it came to COVID. And I think very good things on the horizon. Education is another one. I like to joke and say, unfortunately, you and I had to read books. If you want to throw a domain under the bus, but thermodynamics, I hated it, physical chemistry, I hated it. There's a list of different things I've learned. I hated them. And if you think of the authors, they're not expert storytellers. That is not their expertise. They knew the math, they knew the science. There's going to be a future generation of humans that will be able to learn very advanced topics where when you and I were trying to learn them, it felt like going to the dentist and it was not fun. And I don't think we learned them as well as the new generation. When they're learning concepts through analogies and take your favorite movie character or cartoon character and they'll just roll it into the lesson for you. So I'm so excited on where this goes. Me too. And really, for prompt engineering, I think this is one of those, it's going to be incredibly important. It's a skill set that we're all going to need to know. There will be various shades of ability. But to me, the sky is the limit on the ability, being able to have a conversation with whatever LLM is in the future, the ability to automate of a lot of what you're talking about is tedious. The one caveat I have at all of this, and this is always to LLMs in general, is the concept and idea, are we about to go down a road where we're going to wall off a lot of knowledge? Because we talked about it earlier, the Google Google, the Google payment of ad words, the ability to in effect monetize a lot of this knowledge across the web and Google being able to do that. Even if we're doing unsophisticated prompt engineering, the ability to get to that information much more quickly. And in one location, does that in effect say, and we even saw this with both Twitter and Reddit, recently closing down a lot of API access because of the concern of that knowledge going to others and that knowledge and effect that value not being realized? Does that stop the web and the way we've kind of, we've seen the web up to this point in time just because I can now do the context, I can give the context, I can give the instruction, I can get my answer, I don't have to go to Stack Overflow to do it. That to me is the one concerning point of all of this and that's around just generative AI in general. Yeah, that's an excellent point to bring up, definitely concern going into the future, what knowledge or inputs are feeding these systems. So before Stack Overflow, you had people in earnest that were experts and they were being peer reviewed and they're trying to add a solution. We were all on use net, right? So you know, you would ask it in questions on use net. Yeah. So now in the future, how do you maintain the quality of what's going into these systems? I think that's that'll continue to be definitely a problem that people will be working on. How do you maintain quality? I think Sam Oldman said in an interview, I don't know if it was CNN, there were some other media interview where he said one of his biggest concerns was the human feedback. If you think about things you can control or at least manage and review, and employees is one but 100 million humans giving feedback, a lot of people may not remember the TAY.AI mess where that Twitter AI Twitter bot was shut off within a few days because of human feedback. Yeah, it's really interesting how do you manage knowledge and content and how do you maintain quality? Yeah. Well, again, I would say right now, I'm versus where I was a year ago, I'm a lot more enthusiastic, excited about writing. That was one of the keys for me and just and really prompt engineering and being able to go back and forth with the Chad GPT has an effect to lift that up again. I definitely relate to this. I'm sorry, I didn't mean to interrupt, but another thing you're reminding me of, which is also a really big change that could be coming is writing because pick your favorite author, Mark Mason, was one of mine. He wrote a very famous blog that went viral. That blog was not monetized very well, and so he's forced to write a book, writes a book. It's an extension of the blog. It's a New York Times bestseller. But why would I spend eight hours on audible listening to a book that has 80% of the new knowledge or perspective that was in a blog that is a five or six page blog? And so my hope is as humans working together, we figure out how to monetize new ideas better. So I think that individual, Mark Mason, who had a write a book, very expensive process. He's wasting his time, but he's also wasting all of our time to read this book. And so I'm really hoping that there's a future that you or I or anyone who's listening could wake up on a weekend and based on a mind-meled of conversations they had on a previous weekend or conference, they write a blog and that new idea, which is very valuable, is quickly monetized and they don't have to blow it and make it into a book. Because I think there's a lot of books that could be summarized in a few minutes. Yeah. Yeah. That's why there are businesses that do just that. So, yeah. Jepson, I want to thank you so much for joining us today. Where can the people find you? I'm most active on LinkedIn. Jepson Taylor, you can find me there. I also have a domain Jepson Taylor.com where I try to keep various things about me, past talks, bio galleries, whatever I'm curious in at the moment. All right. Well, thank you so much for joining us and thank you everyone. Please, again, drop us comments. We'd love to hear your feedback in and around this topic. It's one I think we're going to be talking about for quite some time to come. So thank you so much. Take care and have a wonderful day. Thanks, Grant. That was really fun.