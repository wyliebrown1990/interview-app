 When Siri and Alexa came out, they changed how we interact with our devices. Now that generative AI, like chat GPT, is available, is changing how we interact with our tools. All EGPT is observed generative AI assistance to help users troubleshoot incidents faster. Observe users can ask questions in plain English using a familiar chatbot interface to fetch data, extract fields, and make sense of error messages, and much more. All EGPT can even act as an assistant for on-call engineers to remedi an incident via Slack. All EGPT answers users' questions about how to perform common tasks such as finding relevant data sets, or what configuration to use in order to ingest permit theist metrics. Hundreds of users summon all EGPT on a weekly basis, and with the Hubble release, we have fine-tuned it on our latest documentation and best practices. With Hubble, all EGPT provides users with more data insights. For example, highlighting an error message in a log now explains that error message, regardless of source, go language, or web server, or Kubernetes. In addition, new logs often arrive unstructured, so users may have to write complex reject statements to parse them before they can even perform analytics. This can be a nerve-wracking experience during an incident when time is precious. All EGPT not only generates the rejects, but also names the resulting columns appropriately, such as URL or status code. With Hubble, all EGPT is now able to act as an incident assistant within Slack. The incident assistant can read observer alerts surfaced in a Slack channel and take the user to relevant log lines, inspect patterns, and help the user get to the root cause. It can even page the right on-call engineer if required. New users joining the incident Slack channel now benefit from an all EGPT generated incident summary, and when the incident is resolved, the conclusion and a timeline is generated for post-modern use. All EGPT can also save these summaries for future reference, so if an error comes back, the hard-earned learnings are right there. In addition, you can upload your own runbooks, so help can be specific to your own context. Another use of generative AI is OpalCodePilot that was introduced earlier this year. New users can now learn, observes powerful query language, Opal, much more quickly than before. A user who observe can type something like search errors and logs, count by container, and chart it, then immediately see and run the generated Opal code. To power OpalCodePilot, we trained a private language model which not only reduces hallucinations, but it also improves performance and security. Customer data is held within Observe and is not accessible by third parties. More applications are using LLMs every day, so observing the data pipelines, feeding those LLMs is becoming an important use case. Observes OpenAI application provides out-of-the-box content so users can understand latency, error rates, and accuracy of responses that the LLM is providing. All EGPT, an OpalCodePilot, used generative AI to provide a natural language interface for users to troubleshoot incidents. The rich contextual data in Observe makes it easier for generative AI to connect the dots for users and assist their troubleshooting through a familiar chatbot interface. The Hubble release is a big step, but also the first step in leveraging this revolutionary technology.