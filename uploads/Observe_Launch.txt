 Hi there. I'm Cloud Economist, Cory Quinn at the Duckbill Group. You may have no idea what a Cloud Economist is, but that's okay. I made the term up. When you define what you do, that gives you a false position of authority, from which you can insist you're right no matter what the topic is. Speaking of making up a field in which to master, let's talk about observability. What is observability? Ask five people get seven different answers. I mean to me, it's hipster monitoring. For better or worse, that definition is not yet caught on because thought leadership is harder than we thought. The big problem in the space though is that we look at so much data coming in through so many different tools. It becomes one giant painful of glass and there's no good way to disambiguate signal from all of that noise. That is the fundamental tenet of why observability is important and why we're not all just stuck with Nagio still trying to patch it a little bit further like we were 15 years ago. Backing it up a step further. If we look at what observability really means, it means it's time once again for you to find one of the vanishing number of monarchies in the world and kidnap a princess for ransom because you're going to need to do that in order to pay the ridiculous fee. Now what is it going to cost you? Well, that's a fun story. The reason that they're so good at extracting signal from all of this noise is there are so many different pricing dimensions you won't know. In fact, it requires the energy output of a small coal plant in order to figure out the bill for these things alone. But I digress. That's not really what observability is. Instead, let's get observability to find for us by professionals, namely industry analysts. Instead of being paid to sell you things, they have a much more objective perspective because they're paid by people who are paid to sell you things. Let's begin. CEOs realize that their customer engagement models have changed with COVID-19 and some have changed forever. As organizations have migrated from a traditional technology stack to an application and infrastructure environment that includes cloud, multi-cloud, containers, Kubernetes, microservices, this environment is so much more complex and so much more dynamic than a traditional technology stack. When you have an issue, it can be rather like a murder mystery trying to find out what the issue is. So organizations that are doing microservices, they think about how can we pull together all of the information in context to better understand problems if and when they occur. And it has a bunch of new and different requirements in terms of trying to be able to figure out what's going on. It requires a new approach to monitoring. One of the key tenets of observability is really building systems that are designed to be observed and managed accordingly. And the way I like to think about it is that it's really a love letter to your future self or perhaps to someone on your team. It's really thinking about wait a second. Let's try and ensure that the outputs are going to be those that can help us to solve problems. If you want to be an observability vendor, I think there's a couple of key things that you're going to end up having to offer in order to meet demand from customers. So one is scale because especially as end users are in these cognitive environments, they're collecting a much bigger volume of operations data. So you have to be able to scale to be able to affordably collect that volume of data. And a tool has to collect different types of data as well because they're increasing recognition that there's value in metrics and distributed traces and events and logs and errors. So you have to be able to collect all these different types of data within a single system. You've also got to have pretty sophisticated analytics. Then correlating that of course with business metrics, other kinds of metrics so that the people that matter are the people that you can help from a customer service perspective. Or a couple of things from a product standpoint. First and foremost, full stack visibility. Really having an opportunity to collect metrics, logs, traces, external and internal information, really bring it all together in context of an application service or a system. We've also found that this whole theme of it's not just about operational data, but collecting business data, understanding the nuances of the dependencies of different data components of a system. Got observability natives and others that are probably doing some observability washing. So certainly if we look at vendors across a number of spaces, certainly distributed tracing, logging and metrics, all of those vendors are repositioning around this observability notion. You have all of these different kinds of tools, different categories of tools out there. That creates some problems for end users in terms of being able to correlate data that's collected and siloed within these different tools. Then you've got a new set of play that have come in and they're really thinking about observability in a different kind of way. They're coming out of the notion as I say of troubleshooting and they're coming out of observability very much in terms of understanding the behavior of a system from its outputs and dealing with organizations and helping them to have a new way of working. Why are executives thinking about this? Well, the business drivers is really about reliability and customer experience. When we start telling together some of that infrastructure information and the telemetry around the infrastructure or applications are running, with stuff that we're seeing in places like GitHub, where we could take the social coding information and really begin to understand who checks something in, when they check something in, and you can begin to correlate system information with human telemetry. I think that is really interesting one of the things I want to start seeing from observability then is going forward because that's really where the puck is going, I think. Observability is a love letter to your future self. That's incredibly poetic by analyst terms, in sconce, within a love letter to their future client. Now, that future client, Jeremy Burton, CEO of Observe, is going to talk somehow for five minutes or less about what observability means to him. Ideally, at the end of that video, he'll be accepted to college. I want to take just five minutes of your time to tell you a little bit about what Observe does and the customer problems we solve. As most of you are aware, we live in a digital economy. With your product company, services companies, or with COVID, a government agency like Education, you're doing everything online. Every company has to become a technology company. Key to delivering a digital product or service is software, and we build software differently. We use microservices, and we deliver new features every day using continuous delivery. There's never been more change going into production on a daily basis. And when something goes wrong, the customer notices. The stakes are high here because we know that when a consumer has a bad experience online, in 76% of cases, they don't go back. Now when something does go wrong, the scene resembles a murder mystery movie. The smartest guy in the room trying to figure out the answer to two questions. What happened, which is the easy bit, but why did it happen, which is a nightmare? And it's hard to find out why something happened because the date is fragmented. No one, even the smartest person in the room, has access to all of the information. They have to piece it together using their intuition and knowledge, which is not sustainable. But the worst bit is that it costs a lot of money to know nothing about your organization and what's going on in your systems. Legacy vendors charge or volume of data ingested on metric points that preventing you from ingesting the very data you need to troubleshoot your problems. And this is why we created Observe. The current log analytics and metrics monitoring and APM vendors, they're not getting the job done. New problems need a new approach and we firmly believe that observability is that approach. Now when we think about observability, we think about it holistically. We don't just think about cloud infrastructure or database infrastructure. We don't just think about the business applications or the service desk or maybe the CICD infrastructure. We think about everything. Why? Because everything is related. When the custom has an issue with the application, they're going to raise a service desk ticket. The issue may be in the database or it could be in the underlying Kubernetes infrastructure or it could be with the AWS infrastructure. You don't know. So you have to have this wide angle field of vision. We wanted to take a different approach with Observe. We didn't want to become a tools company. The custom has enough tools. We fundamentally believe that observability is a data problem. An Observe is a data company. Now key to everything here is us being able to ingest all of your data. We don't subscribe to this three pillars of observability view, logs, metrics and traces. We treat everything as an event and we start all data together. What we do subscribe to is cloud storage economics. We think you should be able to ingest as much data as you want and keep it for as long as you want. Once we've ingest the data, we shape the data. Why is this important? Well, we didn't want to give users a search box and have you go looking for breadcrumbs. We curate the data and turn it into users and sessions and shopping carts and pods and containers. It provides a much more logical starting point. Most importantly, after we've shaped the data, we relate the data. Behind the scenes, we create a graph of connected data sets and we don't do it using tags. Tags are a nightmare. It's not a sustainable way to join data that become un-maintainable. We think that by connecting data sets, the user can navigate data more quickly and bring all of the context they need to bear on the problem that they're looking at. And finally, we keep track of time. Modern systems are a femoral. Different things run in different places at different times. The question maybe isn't what happened. It's what happened at 2 a.m last Tuesday when the user received an error on the website. Observe keeps track of state of all the components so you can wind back the system to any point in time. You may be thinking at this point, well, observe is this some kind of data tool for data scientists? The answers know we built the interface for the SRE team and we realized that the SRE team may have junior members that are on call and are trying to triage problems in the middle of the night. So we wanted an intuitive visual dashboard approach to allow those users to use the product. But we also recognize that when you're investigating an issue, some of these issues are complex and hairy. You've got to get in and deal with the data directly. So whether you're a junior member of the team or a season member of the team, you can work with Observe. Taking a step back, what Observe does is it allows you to find problems in order of magnitude faster. And we do this because we present things at a familiar and we allow you to quickly navigate to additional contextual information which will help you solve the problem. The example on the screen shows a navigation from help desk tickets right the way through logs, right the way through to even Jenkins builds. And the best news is that we have usage-based pricing. We separate storage and compute so you can ingest data at the cost of S3 and you only pay when you use it. Getting started with Observe is simple. In fact, you can do what you're doing today. But as you drive towards this goal of a fully observable environment, Observe will allow you to keep on ingesting the different data types that you think you need to find the problems that you see. Thank you very much and thanks for listening today. Ugh, missed it by about 10% for the timing, which by observability metrics is pretty decent or so I'm told. We'll be right back after this brief message about a company we're legally not allowed to mention by name. So that's all well and good. But what does this actually mean in practice? One of the biggest problems we're having right now during this global pandemic is that you don't have that moment of frustration watching someone else drive a computer and it's not the way you would drive the computer. Here to help bring that office moment back to you is Belcha to demonstrate exactly how Observe works. Hi, my name is Vagy and I'm one of the engineers here at Observe. Today we're going to take a walk through the Observe solution. For my demo environment, I have a microservices SaaS application running on Kubernetes and Amazon EC2. Right now, I'm an Observe and I'm looking at the different resources I have to start any investigation. Notice these aren't all technical or infrastructure terms. Some of them are in fact related to concepts like customers, tickets, and so on. Well, let's take a deeper look at the customers resource. Here, I can see the different customers that are using my SaaS application. They're all represented on the honeycomb and some more data about them further down the page. One thing that jumps out at me here is that I have some notifications related to these customers. So notification service of items in the data that are of interest, which indicate that there might be an issue. So let's take a closer look at that. I see that I have a number of items here that are coming from Zendesk. So when a user opens a ticket in Zendesk, that also gets sent into Observe where we can tie this back to the customers and the rest of the observability data. It looks like a number of customers are seeing issues. So let's dive into that. The first thing I'm going to do is use this related navigation to drill down to Zendesk tickets themselves. I see I have quite a few tickets here and what I'm going to do now is to use the filters on the right to just look at the high priority tickets. This way I can focus on what looks like my real burning issue. Well, I have some tickets here and I can see which users opened them. What if I could jump to my logs and my application just for these users who have opened these tickets? Well, I can. Because Observe understands relationships between the data it consumes, I can click Navigate 2 and just ask Observe to take me to the logs using teleports. Let me pick App logs here. Now we're looking at the application logs for just those users who opened high priority tickets. But how did that actually happen? Well, Observe figured out that to get from customer tickets to App logs, I had to go through the user and user session data sets. As a user, I didn't need to worry about the path I had to take to get to a destination. Observe simply to care for me. Well, I still have a lot of log lines here though and it is kind of hard to figure out the exact problem. But as we have shaped this data, I have a number of filters available. I'm going to filter on just those log lines that are level severe. Well, now that the filters are applied, I can start to understand what the problem is. It looks like we're running out of memory, which indicates a memory leak somewhere in my application. To validate this hypothesis, I want to look at the pods that generate these messages and see if there's a problem here. I suspect that this might be related to pod restarts. So next, I'm going to use this related navigation again, click on pods to see just the pods that generate these errors. Here, I see that pods that may be causing our problem. I can use this time scover to see when these pods were and were not alive. And it looks like something has changed recently. So again, I see that I have some notifications of interest. Let's take a look. And aha, there's a problem and it does appear that these pods are continually restarting. Great. I think I have something that I can pass on. I know which pods and deployments have a memory leak. And with that, I can tie back to a dev team and pass my work onto them. But I also have my continuous integration data coming from Jenkins into observe. What if I could use that to get right to the problematic commit and build that introduces issue? Well, let's give that a try too. Again, we hit navigate to and use teleport to find the relevant builds. Here we are looking at the relevant Jenkins builds. Notice we have just one event here, because there was one built that introduces problem. I can see that it was Tom who made a change to cache code and it looks like this is our problem. So now I can go right to Tom and say, hey, bud, that cache change commit you did introduced a memory leak that is impacting our customers. I can save where I am in my investigation and share my work with Tom to give him a place to start any further investigation he might want to do. So let's summarize what we just went through. I can see the whole path of my investigation here on the right side on their all applied filters. I started by looking at my customer and then the tickets they opened. I filtered on high priority tickets and then jumped using teleport to the logs for those users. When I filtered on severe messages, I saw a suspected memory leak. So I looked at the pods throwing those errors and saw that they were restarting. Well, to close the loop, I did teleport again and got to the build and commit that actually introduced the problem. This was all the direct correlation in a single tool and that's the video of observe. Tags. Yeah, I fix AWS builds for a living. Let me tell you, tags are the only way to get meaningful signal out of that entire mess of nonsense. Who tags appropriately? Absolutely freaking nobody does because that's a job for computers who set the computers to tag appropriately. That's right. No one has. So it means that you're trying to wind up sifting through this giant universe that's constantly changing and then yelling at people because the tags aren't correct. It's a terrific way to wind up making observability something everyone can hate if you're basing it all on top of tags because it's not only expensive and demeaning, it also doesn't work. Tags. So in case you couldn't tell, tags really torque me off. Now, let's talk to the observed founders about what torque them off so severely in their previous corporate lives that they felt they had no choice but to inflict another observability product on the rest of us. We have tens of billions of dollars spent on machine analytics, but the problem is that the systems that were built were all built decades ago, you know, a decade or more ago and they were built for a different world. And this was one of those things we had butterflies in our stomach. We weren't sure if we could actually build this thing. You talked to customers and they would tell you, you know, yeah, we have an APM tool, we have a log management tool, we have an alerting tool, maybe in some cases they have three or four of these things and nevertheless they still had no idea what was going on in their environment. So one of the common problems with lots of these tools is that they give you no structure. There's nothing to ask about. There's just a giant soup of data. But what people really want to do is they want to ask questions about things. So things can be users, they can be sessions, they can be hosts. There are lots and lots of things in any business data. And that's what you want to ask questions about. So you open up one of these products and as a new user all you see in front of you is like a blank search bar and it's sort of like the system telling you it's like you figured out these dashboards are all pointless. They're utterly useless. Two weeks into using them uses realize that the dashboards aren't telling them anything they need to know. They're generic and pointless. You know universally log management was seen as a very expensive proposition. You pay an awful lot of money just for the privilege of storing your log data. People just keep glomming tags onto data and you get this mass of tag soup. It's a complete mess. We wanted to provide an experience that was as flexible and general as a log management tool but had strongly opinionated workflows like an APM tool. One of the things I wanted to solve is sort of like let's bring it all together. Let's have one system that does it all and not a Frankenstein's monster where we're globbing different systems together. Observe stores all of the raw data with all of the timestamps when we saw it and also optionally timestamps that you put in when you saw the data and based on this we build up a model of what happened over time. What happened when to whom it's a little bit like a crime scene investigation right at the end of the day like I don't really care about the logs per se. I don't really care about the metrics per se. What I care about is the user or the service or the thing that this telemetry tells a story about. Observe needs to figure out how to magically turn that raw stream of event data which we call observations into these higher level resources and historic state of these resources. Now Observe actually has resources we can actually do some really magical things with them. So one of these things is landing pages so we can look at a resource we can look at all of the data in a resource and we can reflect it and build dashboards automatically in a landing page. Time is really front and center if you're dealing with machine boring data. The first technical challenge was well we have this theoretical underpinning of you know the time dimension and the relational dimension how the hell are we going to build something that users can understand on top of this algorithm that there's only like five academic papers on. The challenge with time is that users it's not just good enough to tell users what is the state of the system right now people and don't just want to see the latest state they need to see the history of their system so they can ask questions such as you know what was the state last night when things went down what was happening it's not actually only solving this or two dimensional relations and times it's figuring out how do we present this to me the user in a way that I can easily use and get on with my life and solve the problem get a very short mean time to clue rather than getting lost in all the technical details. So one of the things that resources and these connection between resources give us is the ability to produce some of these magic moments in the UI one of these is the portal feature that we implemented a few months ago this allows you to start with one resource and get to another resource without knowing how the magic happens from an end user perspective it's phenomenal. Getting those kinds of insights out of data that you already have but have underutilized that's an enormous potential of observe that once your systems put their data into observe yes this SRE is going to be the first person who uses observe to figure out what's going on and how can we get better uptime and how can we fast deliver our features but the the user product managers and the marketing team are going to be fast followers and build totally different applications that we haven't seen yet on top of our platform. When you do things that are really profound if you knew how hard they were really at the start you went do them and so we're now proud to show the world something that they're going to be shocked by. AI is a beautiful thing because there's no better way to express the sentiment I hear you have VC money and I would like some of it please that's really where it starts and stops. Now I've long said that any keynote webinar or presentation about a product is going to be shitty if it doesn't feature customers telling stories about what they actually use the thing for. You'll see this sometimes at various conferences the am world sorry so in that right let's talk to a few pre-release observed customers about their experience with the product and why it's not a complete clown show. The SaaS applications these days they've gotten really complex with all the multi-tenancy on the network and the infrastructure that the data traverses through and so many different applications and monitoring tools but you know you can't scale all of that with just people. From the technology standpoint we deal with massive amount of data and we also have the challenge to deliver personalized experience in real time. We recently transitioned our software development efforts to use modern tools such as containers clustering and orchestration which provided us with considerable operational efficiency but that costs visibility. The root cause analysis is just spread around different log files and consoles and monitoring systems and stock traces and new name it so for us to be able to identify what's going on is the challenge that our alerting systems are noisy. Most of my team could legitimately ignore 50 to 60% of their emails and that number is higher for me. Right now we have to go through multiple systems log into multiple things we have a dashboard separate we have a log monitoring that is separate and then we have an API monitoring that is separate right so you have to be able to connect the dots across all of these systems. Application logs are spread across multiple compute nodes we rarely know what node is servicing a client when there's an error. It's really an aggregation problem we need a system to gather data from all of our application containers and store it in one place preferably in the cloud so we don't have to maintain anything on site. With the tool like observe all of them come into one place we get into a dashboard my infrastructure is mapped and I can go from a trouble ticket to solving the issue in one place. Observe takes the idea of event relationships to the next level it allows us to drill down from a big picture view into more granular data but it also provides us visibility in related event streams in addition to providing the standard searching and filtering tools that we've relied on for years. It really helps us with root cause analysis we have a lot of different systems to track log files our uptime we have monitoring and learning system and for us to reach the root cause analysis is just trying to match up those different sources and observe helps us really identify call it the data input in one place. Their whole philosophy is that the clients shouldn't have to write queries or regular expressions that makes me really happy the functionality is available but observe would prefer that the clients didn't ever use it. Generally we don't have a lot of time to write queries and to parse and organize log data that we only use when an application is broken. When an application is broken we definitely don't have time to try to figure out queries or regular expressions. How well they use an experience as being thought up as a very junior support person customer success or a product person I can jump into the UI look at the dashboard see where the problem is and I can almost you know get to the root cause of the problem and being able to provide all of this good you know troubleshooting information to the engineer and the engineer can solve the problem quickly. We believe that the focus that the product has on event correlation and relationships will go a long way to helping us generate useful relevant alerts. That helps us deliver better customer experience in the end. Hello I'm Denise Pearson, Chief Marketing Officer at Snowflake. The Snowflake Data Driver's Awards is a global awards program recognizing innovative individuals and teams that are transforming the organizations and the world around them using data. Every year we review hundreds of nominations from Snowflake customers around the world. Finally, the winners are show sound by a panel of industry experts and Snowflake leaders. Over the last year we've been transforming Snowflake from being the world's leading cloud data warehouse into the world's leading cloud data platform. Our goal is to grow a large ecosystem of companies who are building businesses on top of Snowflake. To mark this shift we've introduced a new category to the Data Driver's Award called Best Data Application and I'm delighted to announce that Observe has been selected the winner in 2020. Observe's SaaS Observability Platform runs exclusively on Snowflake and takes advantage of many cutting-edge features. We're looking forward to working with Observe to enable our joint customers to investigate their applications and infrastructure and order of magnitude faster and cheaper than ever before. As a permanent reminder of this win, we'll be sending over this Data Driver's Award's trophy over to the Observe team. Congratulations. And there you have it. To my perspective, what Sets Observe apart is the fact that they're talking about the pain that they solve for their customers without denigrating where their customers are on their incredible journey. They're doing it without having to spend years explaining it to people and most importantly, they're meeting customers where they are with the problems and pains they're feeling today rather than talking about the far future. I think they're launching today at ObserveInk.com. I'd encourage you to go and sign up for early access, the first 100 people who do get something a little special. But then I want you to tell me whether it's good or whether it's crap. I have problems in case it wasn't blinded in the obvious, but they don't look like most other people's problems. So I'm curious to folks who are running these things in the wild. What do you think about this? I've already been paid. I just want to know what stories you're hearing from this. Is it as good as I think it is? Let me know. I'm Cloud Economist Corey Quinn, and this has been the launch of Observe.