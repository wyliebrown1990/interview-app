 Let's start today with a business update. We've raised an additional $70 million for a grand total of $114 million. Now on the show today, we will not bow to any sponsor. So we won't be disclosing the name of our new investor. But with no fees or minimums and no overdraft fees, is it even a decision? What's in your wallet? We're ingesting 40 terabytes of data every single day. That's three times the amount of information in the Library of Congress. We execute 25 million snowflake queries per day, which is 1% of snowflakes daily query volume. Next month, we scan 27 trillion rows. Now, if a row is a step, we'd have a staircase that would take us all the way to Pluto. We've seen explosive growth in usage, with a 346% increase in monthly active users. We'll be going into COVID in 2020, we had just 15 employees. And now we have 88 employees. That's a 486% increase. All right, so we've been working closely with a big batch of new customers, or the past few months, get them up and running and observe. One of the common requests we've been getting from these new customers is to provide really more prescriptive guidance on how to configure observe to monitor and troubleshoot their applications. So towards that goal, we've been working on our out-of-the-box solutions to support more common scenarios you might encounter, and I wanted to highlight a couple of these improvements. So first, we've greatly expanded on the observed AWS integration that we introduced last year. So now, in addition to the 100 and on data sets that we provide to organize all of this data streaming out of AWS, we now provide dozens of pre-configured alerts to help you proactively monitor your services. And we've also expanded on the breadth of this integration with new support for Fargate backed ECS and EKS clusters, and much, much more. Second, we've released a new solution for monitoring plain Linux servers. Our Linux host monitoring solution brings together everything we've learned about collecting data from plain servers, and includes support for scraping logs, monitoring host metrics like this space and memory usage, gathering configuration information like what packages are installed, and even collecting performance metrics about individual processes running on those servers. We provide out-of-the-box data sets, dashboards, and alerts for all this data, and we even link it with Graphlink to all the content available in our other integrations. Now, beyond these two, we're trialling new integrations for Google Cloud Platform, for Jenkins, and there's much, much more to come throughout the year. We've introduced metrics generated by machines, and with most tools, you feel like you need to be a machine to understand them. A few years ago, I watched an engineer try and build a Prometheus alert. It took them days to get it right, and the end result made little sense to other engineers on call. That's why I'm happy to announce our new metric-alerting experience. It's built by and for humans. We've introduced a metrics expression builder. The builder makes it easy for anyone to alert on metrics, even if they have to do more complex arithmetic. And for the power users out there, you can always dive into the opal and customize your query. Our expression builder takes advantage of Graphlink. That means you aren't restricted to filtering or grouping by tags. You can bring in any related field in our system, like a customer or a user, and do so regardless of cardinality. At every step of the way, you can look at the preview, which will help you understand how the alert would have behaved in the past. We've also revamped the alert page, so it's easier than ever to find the critical information you need when responding to an incident. When we created our dashboarding feature, we wanted to go beyond the high-level, isolated summaries of what's going on in your infrastructure software or business. We wanted to make dashboards a starting point for investigations and insights, not the frustrating dead ends they typically are. Because we understand the relationships in your data, the things in your business and software, when you create a dashboard that panels naturally connect to each other, and relevant content like metrics can be brought in quickly, no need to search. When you work with a dashboard, we continue to leverage this understanding of the things in the dashboard, and use their relationships to connect you to other views of that data, whether it's more detailed dashboards or worksheets ready to continue your investigation. Imagine it's 3 a.m. and you get paged. You open a dashboard and see a giant spike. It should be easy to get to the root cause from here, but it's not. The spike is actually a dead end. When we built our dashboarding feature, we did not want to build another single glass of paint. Observe on the stands relationships in your data, so our dashboards do too. When you see a spike, you can click on it and actually figure out what it means, whether that's a node, user, log, metric, or whatever else you have linked in the system. We keep refining our query language, OPPO, that powers all the data processing and observe, and here are a few highlights. I sometimes want to merge log lines to combine JavaScript traces into a single event, or debounds noisy sensor data. We added a powerful verb called merge events, which lets me do just that. And with Schemaan read, I can always go back and change it later and see it update my view of the past. Once I find the event I'm looking for, I can use the surrounding feature to find things that happen right around the time of that event in that context. When working with intermediate results in the console, I cannot directly type in sub queries without having to make cards in the UI. This helped us build our in-product usage reporting, which is a product feature built entirely as an application on the Observe platform itself. These are some examples of the 20 new verbs and features we built to improve productivity and capability, and you can read more about all of them at our newly upgraded documentation site at docs.observing.com. I'm going to show you that Observe apps are so easy to set up that even me, a six-grader can get up and running in seconds. I love Kubernetes, even though the staples that pods can't be updating parallel, it's a real shame. But hey, I'm just happy that they added an optional label selector to cube-cuddle diff. That brings up to parity with cube-cuddle apply. My friends have been complaining about my Minecraft server going down recently, so I'm going to set up Observe. And someone be happy is easy. First, you go to the Observe app browser and select Kubernetes. I can see here it's given me a token and some instructions and a cube-cuddle command to run. I'm going to fire up my terminal and copy and paste the cube-cuddle command. After a few seconds, our pods are up and running, and the data will start flowing into Observe. Let's go back to Observe and see what we've got. Observe has provided a bunch of out-of-box content. I get alerts for common issues and data sets for everything you might want. Hards, containers, workloads, logos, seed visor, metrics, ingresses, and more. Now, I can get back on my Minecraft server and find out what's going on with Observe. We continuously make efficiency improvements to our backend to save our customers' time and money when using Observe. Some highlights from recent work. A 75-95% reduction in transform costs for resource data sets with semi-structured fields. That means JSON. Incremental streaming implementations of most aggregate functions that includes min, max, average, percentile, and count distinct, which are found in many monitor definitions. Streaming aggregation reduces transform costs by large factor work applicable. On top of these two big optimizations, changes to how we materialize monitor state and schedule monitor execution have led to an overall reduction of 25% in monitor costs across all our customers, where some customers seeing cost reductions of over 60%. And finally, a dramatic reduction of transform task queuing thanks to various improvements to our last-degree source management. Previously, a bit more than 1 in 100 transforms from tasks was queued for 60 seconds or more, which was already pretty good, whereas now it is less than 1 in 100,000 tasks. The net defect is fresher data sets and monitors running and firing more accurately than ever before. Hi, my name is Chris Hain. I'm at the CTO's office at F5. I was thinking about a troubleshooting flow that we'd done the other day through an observed product, and how simple that was compared to the exact same flow at a previous company. That flow was much more painful, and I'd like to tell you a little bit about how that used to work. With Observe, you know, click, click, click, and I'm there with this prior system, it was, you know, an alert hits my phone. I know that the alert data comes from a system. I know the underlying data for that system comes from a time series database. I need to know how to query that time series database for the set of data that I want. I need to know where my, you know, dashboarding infrastructure lives and where all my different dashboards are that might relate to that alert. I need to know where the logging infrastructure is. I kind of narrowed the problem down to a load balancer being the issue, and I wanted to look at the logs for that. So I needed to know where the load balancer logs live, which system that was, it's not in the Kubernetes infrastructure of logs, it's not in the application infrastructure logs. Those are entirely different systems at entirely different URLs and entirely different pieces of software in some cases. So knowing that, knowing how to query it, what I'm looking for and how to get it, it's a lot of things that I have to keep in my brain and kind of know that really just don't have a lot of portability and use anywhere in any other context in that specific job. As soon as I left that role, you know, all of that is just kind of useless information. Observe does a much better job. It's much easier to navigate around. You've got the single pane of glass. You've got these resources that are interrelated. And it's just a better way of operating. So that's my story. So, I'm going to start with the first one. I'm going to start with the first one. I'm going to start with the first one. I'm going to start with the first one. I'm going to start with the first one. I'm going to start with the first one. I'm going to start with the first one. I'm going to start with the first one. I'm going to start with the first one. you