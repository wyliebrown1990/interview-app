 Thank you so very much for that introduction. Let me say it is an absolute honor and always a unique pleasure to join fellows in data science and individuals who are building artificial intelligence. I'm Renee Cummings. I'm a professor at the University of Virginia School of Data Science, a multiple criminologist, a criminal psychologist and a therapeutic jurisprudence specialist. It is my work in the criminal justice system that brought me into artificial intelligence. For many years I was training police officers all over the world in homicide reduction and investigating homicides and gun and gang violence and building communities where we are safe, enhancing public safety and public security. And I would say it is my work in justice that led me into this space because for many years I was using risk assessment tools, these algorithmic decision making systems. And what we were realizing is that we were creating these zombie predictions that were overestimating the risks of impacted communities, overestimating the kinds of sentences that were being delivered. And I felt that the only contribution that I needed to make at this moment was the contribution to future-proof justice. So that is the work that brings me into this space. I will say this to you at this moment. I believe one of the greatest stories ever to be told is being written at this moment and you are writing it. It is a story about power and profit, a story about prosperity and possibilities, extraordinary possibilities about a future that we are yet to imagine. But it is also a story about people, our biases, our prejudices and the pain that often comes with the privilege of the extraordinary power that we have in this moment. An extraordinary and epic story that is being written and that story begins with data. Because data is the lifeblood of artificial intelligence. So let's talk about power. The power is extraordinary. When we think about what is happening in AI at the moment, just about every government is thinking about artificial intelligence. How do we govern? How do we regulate? What kind of compliance should we have? When we think about AI at the global level, we are thinking about the kinds of impact artificial intelligence is having on geopolitics. Everyone is speaking about AI. The president, summoning the top tech executives in the world and asking them to come together, come together with some kind of initiative that looks at the ways in which we could regulate this technology. Of course, generative AI, adding to that extraordinary power. The power of AI to transform just about everything we know about ourselves, this power that's making headlines in just about every media outlet, a power that speaks about a transformation to change this world, to reimagine this world. When we think about the promise of this technology, we are thinking about the great things that we can do. We are thinking about the ways that we could harness the extraordinary promise of artificial intelligence and reduce the risks of this technology. We know that there are extraordinary risks, but the challenge at the moment is how do we negotiate those risks? How do we jump over those hurdles? How do we move beyond the risks and truly exploit the extraordinary potential? How do we capitalize on those extraordinary rewards? The promise is also about the things that this technology can do for this world at this moment. It's about these hybrid futures that we are thinking about. It's about the collaborations and the creativity and the innovation that makes us excited about the things that we want to do. It is the promise of a world that we are yet to imagine. It is the promise of the great things that we can do for ourselves and for each other and for humanity. It is also about the pervasiveness of this technology. And in the work that you do, in the world that we live in, the world of data science, you understand the pervasiveness of this technology. You understand that this technology, there is no pulling back. This technology called artificial intelligence is doing some things that we did not ever imagine that could be done. This technology is creating the space for us to engage in ways that we had never imagined engaged with each other, engaged with the technology, engaged with the machines, engaged across the globe in such extraordinary ways because we have the ability to use data for progress. And that progress is this. There is no AI without data. And we know data is about decision making. That's what we're using data to do. We're using data to make the most accurate decisions. Data is about business intelligence. It's about intelligent public decision making. And if we are to get data right, and if we are to get AI right, then we understand the kind of progress that we could make as a world, a progress that is built on sustainability and resilience and longevity and prosperity. And when we think about prosperity, we are talking about wealth, extraordinary wealth. So we also have to understand that this prosperity has got to be a prosperity for everyone. And these are the kinds of things that we need to be thinking as we think about data. As we think about how do we collect the data? How do we analyze the data? How are we thinking about this data? How are we thinking about the genealogy of this data, the provenance of this data, the historical harms that are often attached to this data? So if we want to think prosperity, we are thinking about using this technology in a most resilient way to solve some of the greatest challenges we are seeing as a society. But as we use data, and as we design and develop and deploy AI, we are realizing that we are now confronted by new challenges. And some of these new challenges will take us into the space of possibilities. And the things that we can do with data science. It's about a future, as I said, that we had never imagined. I would say this to you. In January, I was invited to a conversation, myself, and about 16 other ethicists and individuals working in AI and data ethics. And we were invited by the CEO of OpenAI, Sam Alderman, to have a one-on-one conversation, to engage with him as he engaged with us in this technology called Generative AI. And then within six months, none of us expected, the world did not expect that this technology would have had that kind of extraordinary impact. When we think about possibilities, we think about ways in which we could enhance. We could improve. We could reimagine. We could reposition. And we could do all the exciting things that you are doing with data and doing with data IQ. But when we think about possibilities, we have got to think about possibilities in a collective sense. When we think about possibilities, we are asking ourselves that question, possibilities for who? Who are we including in those possibilities? Who are we excluding in those possibilities? Who are we empowering in those possibilities? Are we disempowering anyone in those possibilities? And when we think about those possibilities, then we understand the extraordinary privilege that we have as individuals working in data science and individuals building artificial intelligence, we have got to think about the kind of prestige that comes with this work. And one of the reasons that many of us are doing this work, but we've also got to think about the bias and the discrimination and the kinds of risks that we have seen to impacted communities, high needs communities, underserved communities. When we think about marginalized groups, minorities groups, when we think about people of color, when we think about questions of identity, when we think about visibility and voice and representation, these are some of the things that we've got to think about. When we think about the privilege that we have been given to work in this space and to build this world transforming technology. With privilege, there is always the unfortunate question of prejudice. And we have seen that as someone working at the intersection of democracy, due process and decision making, working in the space of policing and criminal justice, and looking at ways in which we can use artificial intelligence to build up communities, to create new legacies. I daily, as I teach my students in the master's program at the University of Virginia School of Data Science, we're always thinking about questions around discrimination. And the fact that this amazing technology also has the extraordinary potential to discriminate in real time. In real time, an algorithm can make a decision about you. A decision that you did not know happened. A decision that can change the trajectory of a life in real time. A decision that is often unreverse. We have got to think always about questions around equity, questions around justice, questions around diversity and inclusion. We have got to think about an algorithm and the ability of an algorithm to deny access, deny opportunities, undermine resources. We've got to think about algorithms and data and AI within the context of criminal justice, within the context of law enforcement and sentencing and mass surveillance. We have seen facial recognition deployed in ways that have created an extraordinary amount of trauma in families and communities and of course in society. We've got to think about those individuals who have been wrongfully arrested because of a technology like facial recognition. And then there is healthcare discrimination. It's a big one. It's a real one. Algorithms being used in healthcare, insurance, undermining the treatment of individuals. We're prescribing, doing things that we didn't think it would do. We've got to think about public benefits where we've seen algorithms do some very sad things. And we've got to think about AI and hiring and recruiting and HR. And of course we've got to think about credit scoring. And how do we score trustworthiness? How do we score risk? These are real things for us to think about as we're thinking about the prejudice. And then there's the politics. When we think about AI and data and democracy, democracy is about decision making. Democracy is about the ability to make independent decisions as individuals living in a society. Democracy is about citizenship. That's who we are. So when we think about democracy and AI and data, when we think about disinformation, when we think about the need for content moderation, we are thinking about human rights. We are thinking about digital rights. We are thinking about our civil liberties as we think about synthetic media and deep fakes. And the power of these technologies to disempower large groups and communities. So when we're thinking about data and we're thinking about AI, we have got to think about democracy. And when you are doing your work, you have got to think about democracy. You have got to think about how you're building those algorithms. You have got to think about how those algorithms and those algorithmic decision making systems are being deployed. Because it is important for us working in the space of data science and working in the space of AI to understand that at this moment, we have an extraordinary social responsibility. Whether we're designing products or systems or programs as a collective, we are designing futures. And we must think always that with that privilege to do the work that we do, what we are seeing would be for certain communities, an extraordinary amount of thing. I will say this to you, historically, different communities of experienced data differently. It is a reality. And as we use data in particular, historic data, what we are seeing in the world of AI, the space in which I exist, is the ability for these historic data sets to continue to do an extraordinary amount of harm. The question becomes, are we codifying in the work that we do those biases, those prejudices, those stories of trauma from the past? And we have got to think about in the work that we do in data whether or not we are contributing to the transmission of intergenerational trauma in certain communities. The question of data trauma, it's a real question. When we think about the afterlife of data, when we think about what happens to our data, when we pass, when we think about what happens to our family's data when we pass, when we think about just data in general and the power of data and the power of AI to do the work that is necessary. Now we have got to think about the people because AI is about people and AI is about all of us. And one of the most critical things that we can do is think about bringing a justice oriented and a trauma-informed approach to the work that we are doing. And we have got to think about protection because protection is about safety, it is about security, it's about accountability, transparency, explainability, accuracy in the work that we do, auditability, non-discrimination, and really trying to bring no harm in the ways in which we are thinking. And as we think about legacies and as we think about futures and as we think about the ways in which we're going to design, we have got to think about these data-driven futures that we're building. We have got to ensure when we think about augmentative collective intelligence and we think about the kinds of work that we can do, we've got to think about that relationship between technology and people and the tools that we are building. And we've got to think about the ways in which we are creating these legacies. And legacies are extraordinary. And one of the things we've realized with AI is that AI and data has the ability to either create access or deny access, create opportunities or deny opportunities, create an avenue for the access to resources or deny communities resources. And this is where I ask you to think about three things. Do you process due diligence and duty of care? Because you have a duty of care to society to do an extraordinary, an extraordinary work, but to do that work understanding your extraordinary responsibility. And I'll just end it very simply with this quote. And I suppose that we are very, very familiar. It says, of course, by Dr. King, injustice anywhere is a threat to justice everywhere. But this is the part of the quote that I like, the part that really impacts the work that we're doing with AI and data in particular, everyday AI. Because I saw you had some t-shirts with data shakers and AI makers or something like that. But we've got to think about this. We are caught in an unscatable network of mutuality tied in a single garment of destiny. That's what AI has tied us into. And whatever affects one directly affects all. And that is what I want you to leave here with. That understanding that what you are doing is you are creating hybrid futures. You are co-creating legacies. And as you build those legacies, what you want to ensure that every dream, every data dream is able to be realized and not deferred. I thank you very much.