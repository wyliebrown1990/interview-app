 When interpreting data science outputs, it's important to keep in mind the old adage correlation does not imply causation. Though interactive what if analysis can provide fast answers about a model's prediction, given a new set of input values for exploration purposes, it's risky to make a causal assumption that enacting a specific change to an input variable will lead to the outcome you want. However, uplift modeling, a causal machine learning use case available with data Iku, allows you to measure cause and effect relationships so you can make better decisions and improve business results. Let's say we're a marketer tackling churn. We want to offer a renewal discount to only the customers most likely to positively respond to a promotional campaign, since it's costly and counterproductive to distribute the offer to everyone. How can we effectively prioritize which customers to treat with this promotion? Data Iku has a pre-built auto-ML task for causal predictions, so we can measure the likely difference in outcome with and without the marketing treatment. First, we'll assign the columns that correspond to our outcome and treatment variables. In the design tab, we then further specify the outcome and treatment values for the experiment. In this case, a positive outcome class of renewal means the customer renewed their subscription. And the treatment variable, control value of no discount, corresponds to no offer is sent. Though the design settings for causal predictions are similar to that of other prediction tasks, there are some notable differences. For example, you can simultaneously train a propensity model to predict each customer's likelihood of being treated with the discount offer. As we'll see in a moment, this is important to check because if the treatment is not properly randomized and there are material differences between the treated versus untreated customers in our training sample, it can lead to an unreliable model. For algorithms, you have a variety of causal methods to choose from, including meta learners, with a variety of base learners, and also causal forest. CAUSER models predict both the outcome if treated and the outcome if not treated, and return the difference as the conditional average treatment effect, or C-A-T-E. As we'll see in a moment, this treatment effect is the key metric we care about. As always, after we click train, we'll head over to the results tab to evaluate the models in our experiment. Remember, unlike for other types of predictive models you may have built with DADIQ, these evaluation metrics don't measure the model's ability to predict the outcome, in our case renewal, but instead measure the model's ability to predict the treatment effect on the outcome. That is, how well can this model predict the difference between subscription renewal with and without the promotional offer, all else being equal? With this interpretation lens in mind, let's look at variable importance. The age of a customer, being the most important variable, doesn't mean it has the strongest impact on likelihood to churn, but rather that it has the strongest impact on how a customer reacts to promotions. Uplift charts show us the conditional average treatment effect, as compared to a random baseline. This histogram shows us the distribution of the predicted individual treatment effect. We can use this chart to help us determine an appropriate cutoff threshold for our marketing action. Notice that some customers have a negative treatment effect, so sending them the promotion would actually be counterproductive to our renewal goals. To achieve reliable results, it's important to remember to use a training data set with the randomized treatment allocation. That is, some customers haven't been systematically excluded from the offer for one reason or another. If we added propensity modeling to the analysis, we can assess our data for treatment randomization, to see whether we need to make any adjustments to our training data set. And use positivity analysis charts to further examine treatment assumptions and consistency between predicted and observed frequencies. When customer data is scored through our model, the predicted effect of the marketing action is part of the model output. If you simply want to target a percentage of records with the highest predicted effect, the scoring recipe even gives you the option to specify a treatment ratio. Or from this column, you can set up workflows that help you run and automate your promotion. Although retail and marketing are the best known uses for uplift modeling, you can also use this causal amel approach for fundraising, medical treatment and clinical trials, human resources, and even political campaigns to find those who can be influenced by the right intervention or treatment at the right time. Try out causal predictions for yourself and let us know what you think in the data I co-community.