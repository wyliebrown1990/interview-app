 With the accelerated adoption of analytics and AI projects, it is becoming increasingly difficult for teams to manage comprehensive documentation and monitoring, as well as mitigate operational or legal risks. Now more than ever, companies need governance and oversight to safely scale their AI and analytics projects. In this video, we will explore DataIQ's governance capabilities, giving you the visibility and control you need to confidently and safely deliver AI within your organization. Govern is the dedicated space in DataIQ that serves as a central watchtower over your AI and analytics portfolio. In a single tab, review all models, bundles and projects across your design instances and determine which assets to explicitly govern. Since major business initiatives such as customer retention, fraud detection or claims analysis often require multiple analyses and pipelines, group DataIQ projects under the larger umbrella of a business initiative and review overall program progress in one place. Use the CANBAN view to track project status across all business initiatives. To standardize your approach to AI, create project plans and leverage workflow blueprints with clear steps and gates to explore, build, test and deploy AI projects with optimized speed and value. For each governed project, project owners document its objectives, scope and use cases and add business sponsors or relevant attachments such as model documentation. They also complete a qualification assessment of each project's value, risk and visibility, which we will see become useful across projects in a minute. Assign relevant colleagues from different departments to ensure proper reviews and approvals take place later in the process. This way, you tackle transparency and avoid misaligned priorities or undefined performance metrics that can expose your organization to operational, reputational and legal hazards. For ML engineers and operators, the model registry is a central inventory of all your models, even those imported from outside DataIQ, such as those developed using MLflow. DataIQ tracks not only the version in production, but also subflows for potential challenger or replacement models that are still under development and review. Simply select a model version to review its creation date, status and full roster of performance and drift metrics. The governance workflow comes into play when data teams want to push a new model or project version to production. They need to gather feedback and comments from stakeholders or in some cases receive final sign-off before deployment. If a project contributor attempts to deploy a model or bundle version to production without the necessary validation and approvals, the action will be blocked. The user will be prompted to initiate a review cycle and obtain proper sign-off. By ensuring models meet the necessary standards, the team will minimize the risk and maintain control over the analytics lifecycle. As a project progresses through the development workflow, project managers can add comments and mark finished stages as complete. Back on the governed project page, notice the gauges that show the current status of many projects at a glance. You can also compare existing projects in terms of risks and value with the heatmap view or check the business initiative overview in the CANBAN view. This enables leaders to easily compare projects and make informed decisions about resource and investment prioritization across your organization's entire AI portfolio. In this video, we've seen how data echoes governance capabilities help you mitigate risks and foster accountability in the AI lifecycle, building the necessary trust to safely scale AI in your enterprise. To learn more about data ops on MLObscapabilities, check out the rest of the KKP videos. Thanks for watching.