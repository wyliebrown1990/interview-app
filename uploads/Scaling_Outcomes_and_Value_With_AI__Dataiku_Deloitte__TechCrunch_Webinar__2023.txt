 Hello, and welcome to our conversation on trends in AI today. My name is Minutes of Honor, and I'll be your host for this event. Joining me today is an exciting panel of speakers from both Deloitte and DataIQ. Let me take a moment to introduce the panel. Dave Kuder, whose principal and often lead for AI insights and engagement at Deloitte Consulting, and Ben Taylor, chief AI strategist at DataIQ. Thank you. Thank you. Gentlemen, welcome to the show. Thanks for having us. Thanks for those. Yeah, happy New Year. I think I think we can still use that line for a couple more weeks, right? Absolutely. That's great. Well, before we dive in, let's get to know you guys a little bit. Let the audience understand kind of what you guys do for your day job. And what's the one thing that you're looking forward to in 2023? Dave, what's up with you? Awesome. Thanks, Minutes. Welcome, everybody. Dave Kuder, I've been my day job has been leading our US commercial offer in around AI for the last five years. So spend a lot of day to day helping position some of our most transformative AI and able engagements with a lot of our clients. So have a broad perspective across a lot of our industries. Have a feel for where clients are seeing a lot of traction and industries or traction in some of the differences. I think that we're starting to to notice across different industries and sectors. Yeah, ask questions like what do you look at most forward to in 2023 up until a couple of days ago, I was looking forward to a Buffalo Bill Super Bowl change. Now that that's a thing of the past. I think what I'm most excited about is roast AI for 2023. And I think we'll touch on these topics later because there's a lot of newer technologies that are getting a lot of prominence in the press. It has to do with adoption and are we at a inflection point at its core. A lot of AI related implementation has to do with probabilistic outcomes has to do with not every answer is right all the time. And I think a lot of consumers of applications are used to binary right or wrong and thinking those terms. And does that really start to turn the tide of acceptance and adoption of a wide ranging amount of technology is as folks get more comfortable with that aspect of AI in their lives. And you see a tremendous really fueling of use of a lot of these technologies in different areas. And I think adoption will be a big theme of our conversation today. So, before to. Awesome. Ben. Yeah, I'm excited to be here. Ben Taylor. I'm a startup that I've worked for. I started my career at Intel and Micron worked as a quant as a head at a hedge fund. And then I joined higher view as their chief data scientist, there's a quiet company. And so I've really celebrated jumping different industries semiconductor, quant finance, HR, then I did my own startup where you learn all the things marketing and sales and customer success and all the lessons that make you cry. And then data robot through acquisition to and half years. And then data I could recently so I work as the chief AI strategist. If I do simplify what my focus is 80% of my activities are focused on go to market and sales. So driving attention I travel around speaking I'll be speaking Saudi Arabia at the leap conference in a few weeks. And then sales is really fun executive sales convincing executive teams that a is worth betting on, which I think is a pretty easy argument, but often that argument isn't done well. It's done by technical people that talk about how things work. There's no urgency. And then I care a lot about partnerships and health care. And I also have a selfish interest in finding joint marketing projects that awaken the inner child. So what what are really cool things we can go do and then just a few justify through the lens of partnership or brand building that that's the stuff that it that's the candy I'll pull out of the bowl and I'll deal with the rest to make that happen. Awesome. That's great. Very wonderful. So so we coined this topic around AI trends and you know, when it is start with a couple of key highlights from a study that we had deployed have been driving for the last five years. So annually we do this study across 2500 plus executives and the industry. 13 different geographies, you know, six different verticals and and one of the key things that came out of the survey this year, most strongly. So is that, you know, almost 95% of the audience or respondents came back and said that they feel AI is going to be critical to their success and from a business perspective. Now, if we dig deeper, we also then looked into what are some of the segments that are associated with AI adoption. So, you know, for folks in the audience here, if you look at the slide, there's the extent of the by axis and and you know it's really more about, you know, when you think about the adoption rate. That is essentially what you're seeing from, you know, on the y axis, right, starting with the starters at the bottom left. And then as you move up, you know, you have more applications that are AI fuel. And then you ask you go on the x axis to the right from the left you start with, you know, people that are seeing marginal success in terms of business outcomes and then to the far right are our companies that have seen an amazing amount of success in terms of, you know, building profitability. Driving new businesses or even increasing their top line and customer experiences. So when you think about kind of how the, you know, the audience is split up, you know, obviously, you know, these are fairly evenly distributed. You know, this is about 50% of the respondents that are seeing some significant advantage in terms of business outcomes. And then there are others like starters on the receivers who, you know, seem to be kind of trending not as high. And so when you look at the trend lines, which we're actually showing the next slide here, we call out the path seekers and the transformers as really the high outcome businesses, right. These are companies that have, you know, four to seven plus, you know, different types of business outcomes and applications that they've been driving, whereas the starters and under achievers are still kind of trailing along. So my question, you know, Dave to you to start with is I mean, you, you talked to a lot of these businesses on a daily basis. And what are you seeing as trends evolving and deal aligned with the observations from the survey. So I guess it's interesting as I looked at this and that I guess one of the first primary hypothesis I have is as you've seen adoption increase. I think you see a bifurcation of where expectations are related to high outcomes or high business outcomes. And I think you have, I'd say more reasonable expectations around the high achieving organizations and they're generally the ones that are either more focused or more experience is what you're starting to see. It's those individuals in those organizations that recognize the amount of work that really needs to be done to drive a larger scale, more impactful production implementation of AI. And that's what you're starting to get a sense of. And I think there's I'd say three underlying drivers that organizations are our rest one with their or trying to overcome, I guess when you look at the lower outcome organizations. The one is I refer to it as the myth of use case zero. You see a lot of organizations that are just that have just started to dip their toe in and are looking for the singular use case that are all the ROI for the organization is going to be self funding. And there are those and there are especially when you take a look at core product and service development. But by the way, those are pretty obvious when you think of investments in AI related to autonomous self driving vehicles. It's obvious. It's a center of the core value proposition for the service or vehicle. But for ones that are more on enterprise enablement operational efficiency. Those are about taking many smaller bites out of the apple and it's about foundational infrastructure investments that especially lie around the infrastructure and on the data side to enable not just a single use case, but multiple use cases over time. And a lot of that stuff comes up from and it turns out the ROI on your first for a is not going to be as large or sizable or going to solve the world's problems there. So I think there's that only the second one I refer to is it's the adoption and explainability challenge. And I think it's an under estimation of what that challenges in driving a business outcome where you might have. In AI use case that generates the most insight and the best volume. But if your if your teams are not taking advantage of that, you're actually not seeing the results. And it's kind of the last mile of AI implementation. In example, that would be you know, if you had, for example, a next best offer or next best action or a lead generation model that was perfectly ideal, by the way, it works 70% of the time. Are people only using it 10% of the time because it turns out they looked at the 30% that failed and said, you know, I can make a better a better answer, give a better answer myself to be able to do it. In recognizing that change management, that's kind of what I started about with the intro was the just the acceptance of not being right, but being right more often on average. So I'm going to take advantage of the tool that's there. It's a big deal and it's a big hurdle on the change management side for organizations to overcome. And then the third element I'd offer up my nose when I think about over and underperforming is is recognizing at its core for those use cases that are not central to product development and service delivery for an organization. Recognizing the nature of where you're going, you see a lot of organizations, they base their business cases around cost. Why do they go around cost versus revenue, it's easy. I can absolutely quantified at the end of the year, I know I've either spent less items from a third party, your services, or I've used less people to actually get it done. It turns out in just kind of the automation and efficiency if you talk to like productivity, we're at the pinnacle there. A lot of the opportunities that organizations are going after that are driven by underlying cost savings there are the most complex. It turns out the when you start trying to remove people from the equation for many businesses, it gets really thorny. Why? Because the individuals that are left in many businesses don't do a single thing. All those tasks and activities, those have been automated over time through enterprise systems and platforms. And those individuals are dealing with the ultimate complexity of the business. Those are things like, I've got multiple states, I got multiple regulators, I got different customers now that I wasn't going after before and I got different lines of business. And that's when naturally people are filling in the gap there. And a single technology solution isn't going to allow in mass for us to replace a lot of that work that goes on in organizations. So it's recognizing, especially those cases that are focused on that on the cost side are going to be difficult. And I would offer on the revenue side, I see a lot of over zealous organizations worrying about attribution models that are inherently in precise and in challenging, especially when you start talking about revenue and how much to this specific implementation drive something that's really a complex dynamic in the marketplace. I think that that's when I guess I'm seeing these and how I internalize those those results. No, that's great. That's great. I mean, it's very pragmatic in terms of the approach and obviously, you know, game, depending on where the organization is, I mean, that in the industry, you know, those results may vary and the adoption, you know, kind of follows that. So Ben, I mean, you know, given that a data, I could mean you guys are one of the, you know, leading platforms for data science and obviously as it as a, as a chief as strategist, you are probably talking to a lot of, you know, these customers in terms of, you know, the industries or the different types of, you know, use cases. And so do you corroborate with the, you know, with the results of what is showing here in terms of, you know, where is the market headed and what type of, you know, high outcome versus low outcome, you know, clients are you, you know, seeing in your day to day life. Absolutely. I agree with the results, but I also agree with, I was nodding my head and smiling with a lot of things David was saying I, it's, it's, it's so interesting. The problems that exist in the industry, a lot of people want to stick their toe in the water. They're thinking of a one in done, they want a eyes a checkbox so they can go tell the board or, or you know, one of their managers that we have AI because there's a data scientist over there. And it's transformation is on a different scale. So transformation for people that are truly winning the AI game. They have a center of excellence. They have a hub and spoke air every department. It's not about a siloed AI use case. They're, they really are catching the vision that every process within a business potentially could be impacted for good with AI and the, my two favorite discovery questions talking to the business, where's your growth bottleneck by human capital. And what is the number in your business where a small change would make you excited and it's funny because I didn't have to say anything about AI. But if you can really begin to have those discussions with the business. Now, now you're not talking about one in done. Now you're talking about many, many problems in a way that's much more defensible. But I, I think on the sales front, I'm sure Deloitte agrees with this too. When you're selling to different executives or different leaders, you really love to run into the visionary, right. The person that gets it, the person that is a risk taker, they have enough emotional capital, they really drive it forward. When you run into someone that is a little bit more cautious. I've seen this before where you're talking to an exec. They'll take on the attitude of, I don't know if AI is quite ready. I don't know if it's quite ready for me to bet on. And it's interesting because I want to respect where they're coming from because if we really open open the door to why are they saying that they've had three fault starts internally. I don't fault them for having that attitude, but. And I think that's where you have to divide the market between what you're what you're seeing in the results. If you're transforming your winning. If you've had fault starts every industry out there is winning in the AI today. And so if for people that have had fault starts if they're disappointed. They need to look into these results. They need to understand the companies that are winning. They need to reach out to companies like Deloitte and did IQ and understand for my industry. What are people doing. That's that's great input. And again, I think when you think about, you know, obviously the use cases right in the industries those were you know by the you know the type of you know focus area that they're driving, you know, for an option perspective. So, so I think in terms of, you know, so we talk about, you know, high outcome, where so low outcome achieved, you know, companies. I'm a little more about the industries because this is where the rubber means to vote. This is essentially where business processes are getting impacted new. You know, businesses are being formed or clients are being supported. And so, you know, the survey also pointed out some of the top use cases and again, these are marginally, you know, there's a marginal delta between them, but across the board. If you think about, you know, whether it's using voice assistance or recommendation engines prediction. You know, predictive maintenance or use cases associated with customer activities. You know, how do you, how do you correlate with the use cases that you're seeing out in the market and maybe Dave, I'll go with you first, what are, what are some of the top use cases in industries and how does it vary from let's say a life sciences industry to a consumer industry. Yeah, I guess let me introduce I guess a couple of big observations of trends across industries. One of the ones that I see is a trend between high capital intensive industries in low capital intensive industries. And that has to do with areas like our wine business case that we're talking about beforehand. When you think about, for example, high capital intensive oil and gas automotive industries where when their investments around new and let's say a new factory new building, you got a platform that's going to be in production or multiple years, you're talking about hundreds of millions of dollars. And it would be reasonable to aspire to an investment, let's say in a, in a, we call limited reality or a metaverse related opportunity to simulate those operations. And to be able to fine tune and drive really the pinnacle of efficiency and delivery. And in a context of it would be different for an organization that is, for example, a beverage manufacturer that their actual value of the inventory that's moving that line is a fraction there up. But that just doesn't apply to virtual reality applies to, for example, predictive maintenance. It's the same thing. What's the value of that use case for something that hitting an auto line where the value of keeping that up is $10 million an hour versus to $100,000 an hour to advance that in. The cost of implementing a solution there, so we see high capital low capital intensive, a little bit of creating a differentiation in some of the use cases they're going after. There's some industries that I would say are much more interested in explainability and those tend to be around the financial services industries that are dealing with risking regulatory. They've been at this for a while and they ultimately for some of their core business operations. Ultimately, we have to be able to explain to a third party why they're doing what they're doing in order to be able to put it in. It's a, it's a bit of an impediment if you think about from even using some of the most cutting edge when you start talking about deep learning and getting into those core processes. Because if I can't explain why I made an operational decision, I'm not able to actually use it in my operations delivery. So figuring that and cracking that nut out is there and it creates, I'd say, an over indexing of use cases and marketing and sales where they're able to invest and be able to use. I'd say some of the more cutting edge areas. I'd say in technology and media in some of those areas, you're starting to start. You continue to see high investment in that core product development service delivery. So I think of the center of R&D where it's at the focus of their value proposition to customers. So in a fundamental different area that you're seeing there of how they're investing. And then lastly, I would talk about healthcare and life sciences. Continue to see tremendous investment there in personalization, marketing and sales when you think of the core last couple of decades have seen a lot of trends in mass personalization and manufacturing. But I think you're seeing some of these industries starting to push the envelope on mass customization or mass personalization when it relates to service delivery. When you think that the next generation of our healthcare life sciences, the library, that's where you're going to see a lot of the advent where you're seeing a lot of focus on those types of use cases. Are you seeing something similar? Yeah, one of the thoughts I had listening to you, David, was when you get into some of these very high value use cases, think oil and gas. There are massive wins, $100 million wins attached to a single model. And if we if we're in the room, and if I, and if a data scientist announces that we've found $100 million win, $50 million win, etc. For the people that are excited, I would say you're still living in the experimental land. For people that are applied and you talked about the storytelling and in the last mile, and I see you nod to your head, you know where I'm going with this for the people that are applied. If you're telling me you can you found a $100 million win on my training day set, what are you going to do this weekend? What are you going to do when I'm with my family on vacation on a town or all the engineers are because if you can go this way, you can go that way. And we see examples of that sometimes and that's, but I don't want to scare people because I feel like companies like data, and Deloitte, we are taking this very seriously. Like we, we aren't optimists, we're realists, and we're approaching this in a way that I think is responsible. So huge ROI wins that are out there, very exciting and different industries, but there's always two sides to that. And so it's important to come, it's important to partner with people that have paid the tuition and listening to you, David, it's very obvious that you've paid the tuition. And I'm sure there's I'm sure there's some pain attached to that as well, you know, mistakes in the past and things that don't work out, but that that makes you a very trusted partner. And I saw the slight change, maybe I'll speak to this briefly. So. Before, before I address, we have two case studies I want to talk through case studies are good, they're inspiring, they show traction, attraction in every industry, there's libraries of case studies, but the thing I would warn people from is if you're waiting to get started until you see your exact use case, you're waiting too long, it's already too late. There, and we could talk in more detail about why that is, but for this particular case study, rather than starting at the beginning, let's start at the end, 40% increase in efficiency, cost reduction, this is dynamic audit planning, something that took months is now has now been compressed, it's been accelerated. These are the types of question, so how would we have found this case study going back to those questions, tell me a process, where's your growth bottleneck by human process, if we could have more people auditing, that is a process where we're bottlenecks bringing AI is a great solution. So I won't spend much time on this, but by bringing AI into process in a business, it allows you to do a few things, you're leveraging your experience, you have a lot of data's experience, just like people in the span will have experience to make better decisions, and you can accelerate that. And something that isn't as well known, I took some, it's interesting, if you backed up, I used to run into data IQ on the competitive side, and you form opinions of competitors, if you think your competitors better, you should quit, but I didn't think that at the time, and when I really looked at data IQ, when I really looked at the product finally, I was so impressed with their ability to integrate, to collaborate, there's the evolving tech stack that changes every three years. I can tell we're old enough to be on the call to remember the who do promises of a doop, the promises of redshift, and there's always something else, and so it's important to build a tech stack where you don't have to fall prey to that if. Let's actually let's go to the next let's go to the next one i'll go a little bit deeper on that so with this, if you have to task your team with utilizing pie spark is your team qualified. Have they had that experience before or are you having to ramp and pay that tuition so having that integrated into a platform like data IQ I love this one, I actually selfishly have an interest in health care. Because we're all going to die, and if you move the needle in health care, yes, we can make banks a lot of money, yes, we can make well and gas a lot of money or pick different industries, but when you make a difference in health care. Lives are impacted so the value again working backwards 10% increase in instrument performance and so instrument availability by building these a models and if you can. If you can improve instrument performance by 10% that impacts time saved but also impacts life saved going into surgery is a very but it's a dangerous thing you don't want to be in surgery. Any longer than you have to and if you can carve 10% off that may not sound like a big number to a lot of people that are listening, but there there are industries where smaller numbers have massive impact. So the the challenge that the team wanted to do they want to analyze this image kind of instrument there were some preset settings that they wanted to optimize. And I'll wrap this up quickly, but one of the things to think about is experience and intelligence in general so normally you'd have people that are trained to use these devices, you might have different settings where they figure out through experience which settings are better with a problem with what I just described that's trapped in a human. And if it's all trapped in individual humans, are you really benefiting from sharing the combined knowledge. Because it's a little hard to understand why we do things and if I have you can have intuition, I can have some limited experience, but humans are also plagued with bias. So if I decide that this is the way I do it, it's not a very defensible way compared to this approach with data. So I really would rather open the discussion now and turn it back to you, Monosh on what do you guys think about when you think about case studies or have you run into this David when you're talking to an executive fire and they're being very, very stoic on until I see my case study. You can't solve my problem and you will and you and I know you can solve their problem and you have so many case studies that they're very similar, but they're have you seen that before where they're really they're being stubborn unless you have their exact case study I'm curious if you seen that. Yeah, we have and we've we've dove our toe into ways to overcome that where if I don't have the explicit qual in my library or I haven't done exactly that. Figure out a way to get started with a proof of value to demonstrate and there's a lot of skepticism on it worked with somebody else's data will it work for my data. And demonstrate the value so we seek to overcome that I was that it's interesting at the end of the it's almost gets back to menose where you started with of like under performing over performing it's interesting a lot of the new entrance that are coming in. And to the game here I almost feel like AI was intended or is anticipated to be for a lot of organizations differentiator and in a lot of areas it's become keeping up with the Joneses and I spent a lot of time and effort here and it turns out the feature of the capability I just added just made me on par with my competition because it was an expectation now of my customers or at the same time it allowed me to cut my cost of goods sold here. It made me more efficient in my sga service delivery but it was absorbed because I had to lower my my prices to be able to compete with my competitors it's just the standard I would say competitive dynamics within the market that a lot of what are intended to be fast followers are coming to the realization of it so then it's it is really hit when you talk about like medical device and surgery. How long is it going to be until every provider this is a core presence in their operating room and oh by the way they've had to be able to compete with this effectively and they're behind the game because they haven't seated and they were waiting for my surgery centers fundamentally different than this surgery center so I have concerns here about being able to put it in versus thinking about you know I need to stand up this is a broad capability for all of my surgery centers it's something that I'm going to need to get back to my experience. I'm going to be able to compete and it goes down to the the perspective of incremental improvement many bites at the apple versus the one single use case here that's going to go to solve them all we're going to be what I'm going to be able to hang my hat on to the board. Yeah, I did you might have I jump in there there's some very exciting things you hear. Because you bring up an excellent point if everyone's doing AI and you're last to follow how are you supposed to be competitive and you really drive that home at the end it's. If you have one model in production this year all year you don't change it when your competitor is evolving that process and iterating with their subject matter experts collaborating and they're on their 50th version and they've added new features that you have not added and so it really is about those iteration cycles or those incremental gains. Yeah, you said everything I just wanted to kind of jump in that absolutely agree beginning to end. But I love the point that you brought up how how should you be competitive everyone's doing AI so how are you competitive I love that that that thread to pull on. It's almost the journey that I see clients go for is there's the exploration to your point dip in their toe in then there's the focus on efficiency so how do I get better faster and be able to drive down the cost my deployments and then it's how do I scale and get this across everywhere. It is kind of how you see clients going through that adoption curve there and just different focuses at different points of time of where they're where where they're applying a lot of resources to get the most bang for the buck. Hey, so I want to take a moment to remind our audience that you know there is a Q&A button that you'll see on the screen so feel free to continue asking questions I think this is a great conversation you know been in Dave so I want to take this a step further right because when you think about efficiency and I know Ben you mentioned you know where you're you on in the conversation about that check box right that organizations may be looking for if hey I have a data scientists and so you know good from an AI perspective. But I think the challenge that we see in a game this has certainly been accelerated with the global pandemic and everything else that is going out out there in the industry but a notion of you know this terminology called a citizen data scientist right has evolved over the past couple of years and I know you know Ben you guys are data I could have been you know driving that quite a bit I'm just curious for me perspective you know how are you seeing organizations adopt that right because there's only so many data scientists that you can hire or or train and I know you know I'm going to take this a moment to ask you to do that. It's just that I think that the challenges that you can have and I think you can also try to figure out the needs of AI are now you know weaving into every process of business and so how do you how do you make that transition and what are your thoughts on this new you know technology that's out there. I'm also kind of saddened by the history that's existed in this field. I a long time ago when I was the Chief Data Scientist at Higherview, every member of my team had a PhD in physics. And we are tackling these interview prediction. We're working on big problems. We could not do any AI solutions for any other department. So customer success would come and say, Hey, can you build a turn model like something that's laughable, right? Like today, but I'll build it too during lunch. We could not do anything because the opportunity cost was unthinkable. We're working on these seven figure contracts. They are the most important thing. And it was very alienating. We couldn't talk to the business. So the citizen data scientist democratizing AI. The final point I'll leave on that thread is I've gone from believing that everyone that was going to do anyone that was going to use AI needed to have a math minor period. To every process owner could actually run an AI initiative. I don't care what their background is because it really is the standing on the shoulders of giants. A lot of the details of how the models work with the models are. And I think this sad reality that shows up towards the end of the story is, would you rather have a better model or better data? The extreme techno files over here, they're going to chase a better model to the nth degree and e-cout an extra part. And I think I'm sure listening to David here, you want defensibility, you want execution. But also you want the business bought in. So if I'm a data scientist showing up at the table and I'm nerding out about some brand new model on the market. That is not helpful to you at all. And it's definitely not helpful to the business on the other side. So I'm a huge fan of the transverse seeing best ideas will come from people outside of the data science group. It took me a while to get there. I'm sorry I used to be on the extreme. Dave, what are you seeing chief data officers, AI officers or even CXOs in the organization? How are they adopting to this new wave of machine learning engineers or certain data scientists? You know, I think in my conversations, I think it's a tough balancing act for them. And I think a lot of more balancing it. And on one side, they are seeing the trend and allowing them to fuel it allows them, as you can imagine, these capabilities sitting closer to the business allows your business to be more nimble. And I think that's the key to responding to the market a lot faster than a centralized team that Ben was was looting to earlier. And that's the reason because you're allowing yourself in your spreading that capability throughout the organization. I think there's another huge benefit they were with on the positive side. It is trending towards the upskilling of your organization brought me. If you're not expanding that capability, you're not taking advantage of a lot of the knowledge. And frankly, where everybody expects and starts to see the ingenuity and utility of a lot of these capabilities that exists. One of the one of ones I guess I'd offer up there is just been interesting to me because it's been a topic of conversation over the last several weeks. Everybody's aware of the press that's in the market around generative AI hot topic of conversation. You're seeing a lot of of utility there. The interesting, I say observation is there's a lot of focus around the use case that has to do with question and answer prompts and whether or not you get the right answer and how often is it right or wrong. One of the interesting utilities from folks that have leveraged the tool is the ability to not even prompt the ability to just leverage that tool for here is my text. Can you put something else out I was talking to a colleague who had sport over hours, put an abstract into the tool that they had done in what came out was markedly better, markedly more intelligible from taking deep technical detail. Down to there we've had a lot of I'd say non native English speakers leverage this to be able to enter in their text and get out something much more interesting and I haven't seen just a lot of that in the popular press. But the reason I guess I bring that point up it's the underlying use cases or utility that when you start talking about citizen data scientists that a lot of CDOs and CIOs are hoping to take advantage because it's knowledge in the business individuals that are close to your customers that actually don't have some of that insight that you're open to apply. But that is traded off I'd say with the other side when I said a balance at balancing act on the other side, I think CIOs and CDOs are concerned with privacy and risk. All right, I start doing a lot of enablement I have to be very careful with my customer my consumer data and privacy and how do I enable it how do I anonymize otherwise mask data that can be generally leveraged by the organization to be able to drive inside. I think there's concerns on the cost sum in the concept of it's been an optimal trade off the concept of shadow functions popping up in how do you wrestle with that. And then finally, you alluded to this it's the capability of explainability it oftentimes some of these tools are putting in the hands of some of these observations. If they're not interpreted correctly, you can make faulty assumptions around what what these tools and what they're actually telling you without a combination and so when when I can ask what's the right answer what's the right operating model. And this is the the consulting truism of it depends and it truly depends a lot on the individuals it depends on the data it depends a little bit on your business and how it's structured. Because the right answer is not going to be the same for every organization in industry or or sector because those variables are going to go on a really push pull. I think how fast you can go in these areas and I at the center of it, I think at least what I've seen has to trust has to trust between those two different areas of how how fast you're able to go. I don't know bad if you've seen similar things. I guess that's what I pick up in my conversations. Yeah, I've seen similar things. There was one thought I think that compliments what you were saying. It is going to depend a lot going back earlier. Sometimes I'll find examples where someone will try to press me for model performance or though they'll try to press me on a timeline that if you delivered you know $50 million and four weeks over here, can you do it here. We don't know like that's the honest response we we have no idea we have to it depends we have to get in we have to understand the data and the team. One of the things I wanted to throw on that I think compliments what you were saying there's also a lot of politics internal politics that are involved and there are change management antibodies that show up that because people are they're used to process they have what they're doing. And so I'm a big fan of top down a top down mandate. So getting executives bought in because that'll help with some of the change management antibodies, but also bottom up evangelism can be quite powerful. So having the business finally understand AI through the lens of a business because if they're hearing it from deep tech data science team. It's confusing. It's a distraction honestly. It is a distraction from the core business. I think the politics are fascinating. I think people that are very successful top down mandate bottom up evangelism. And the collaboration which I we've mentioned a few times it you need that storytelling you need the collaboration and it's. And I've learned that if you ask of a process or model is working a data scientist will give you a statistical metric and that is not how you want to defend these processes you want it to go through the lens of the process owner. Because of a process owner or subject matter expert can defend the model. Then that I would say that's very close to something that could go to the CFO or at least go to the CEO and AUC score. Throw any statistical metric out there that the audience likes and I've seen disaster on the high end. Right, like. That's yeah, that's awesome. Yeah, I love the dialogue right in terms of how this field is a wall word of period of time and you know, it would be remiss for me to not ask the question which we don't oppose at the beginning of this session, right, which is what's in store for 2023. You know, Dave you alluded to gendered away. I mean, you know, there's not a day or you know any press that's out there that's not talking about you know evolving trends and large language models and chat GP and so on. But I think a question that I would have, you know, and then maybe this you know goes to you from a tooling perspective and technology perspective and yes, technology is one component because as the culture of the organizational change. Here everything that goes into change management, but when you think about you know, let's say the last you know 10 15 years of evolution in terms of how data science and modeling has progressed and you know how. So clients are becoming more and more comfortable in asking the right type of questions and in this even terminologies like prompt engineering coming up. So if you look at the evolution of a K at some point you needed a lot of data you had specifically trained data scientists to build the models to you know get the answers that you need. So now moving into the continuum of let's say citizen data scientists that are getting better at you know asking the questions. And now we have solutions like gendered AI where you ask a question and gives you an answer based on the data. And so you know what do you see as the future of how this technology is evolving to the point where you know AI is obviously democratized it's in the fabric of organizations. And yet there are barriers for you know for them to be fully you know becoming AI fuel right what do you see and you know going forward in terms of how let's say you know somebody like data who is looking at leveraging some of these capabilities or augmenting you know what you have to offer. So I'll speak on data IQs behalf and then I'll speak on been Taylor's behalf. Or but because I I so when I think of data IQ they have. So there's certain themes that you can see where we're going if you look in the past so data IQs and a great job expanding on data type data source. So number of problems AI problems that they can tackle where they've got evidence of case studies following behind continues to widen so industries will continue to widen data types data sources will continue to widen. Time to value will continue to shrink so by time to value time to value to who to the business like how do you get meeting ready how do you get to report how do you get the defensible feature importance plots or the sharply prediction levels. How do you get that stuff for the business faster and if there's new technology stacks coming online how do you integrate with them even better and so you're you're going to see deeper integrations but if I have to now maybe take off the data IQ hat for a second if I'm a lot to do that if we lean into the future. Time to value will continue to be compressed to the point that user interfaces are non-sensical. And to lean into it so if we if we made a billion dollar bet or a 10 billion dollar bet and if you went and created these product engineering teams season founders we built five of them and they went out and built the AI platform of the future well customers going to have to learn that right and it can be very intuitive but it's all going to be different and if you can press time to value to zero now you're dealing with imagine like Jarvis for everyone chat GPT. If if David and I are in a room working on an AI project we're having a conversation but there's real time feedback on a screen because you want to make sure that it's following a comprehending what you're trying to do when it comes to getting access to data sources or comes to doing different things there's going to be a lot of anticipated action so in that value for a data to delivery. We can someone whose experience they can make decisions oh I think this is this insurance loss data set or oh I think this is this good thing we have the business here but you're going to see a huge wave of anticipated action where AI is maybe this is me being completely out of control but I hope in the future five years 10 years 20 years from now maybe you know we're at you know we're all hanging out together we're drinking a wine we're watching the sunset. And I turn and talk to my home and I task my home with something that would be a PhD thesis today and then I go to sleep and I wake up and I review the results of a breakfast I think I don't think that science fiction but some people might think that's way over the top David I'm curious how how do you react with some of these themes of time to value going to zero or things that feel nonsensical is are you and I going to be alive to see something that ridiculous. No, I think I think we are it's like I guess when I think of those themes around menos when you talked about like becoming an AI fuel organization and is then you talked about some of the the visionaries that are out there. I think about the precipice of when we overcome some of the obvious things we one of the themes I think I've been talking about today has to do with users and has to do with adoption or organizations underestimating. That and I think about think about your most basic use cases like propensity to purchase and I think what our users need to see is it doesn't matter how accurate a model is if for example on the life insurance agent and I want to know who to call tomorrow. Your model needs to be able to explain to me why your list is better than me looking at the obituaries in my local paper to understand who passed away because I know for my last 20 years in the industry. That that behavior or somebody recently passing is a strong propensity to purchase. And so there's these heuristics in our business operations for many areas that folks need to overcome and that's where again really excited about adoption because I begin where started I believe we're beginning to start to be able to approach. Understanding of it and I also think about man this topic of conversations been going on think of. Spoke professional sports man analytics when to use it when not to use it. I want to say it's been at the precipice or at the top of everyone's mind for probably the last decade there and gravitationally increase to get reports on which organizations are more or less a tune to using it. Correlated with success and you're just gradually seeing like an entire industry start to move up over time. And when you think about time to zero time to value. Yeah, I think we're I think we're hitting close there. In terms of this is going to be next year the year after but when you start thinking about some of those areas. I do think I guess Ben when you said that what pops into my head is differences in expectations I see one of the most fascinating stories have had her last year we had a client organization experimenting with a new AI technology that say that the counter intuitive observation was this thing was working let's say 70 to 80% of the time perfectly. Those individuals and new to the organization that we're working with it thought the solution was the was poor didn't work didn't want to use it. Everybody that had been tenured in the organization had to deal with the previous process the way it was had to in this case engage with customers love the solution. Realize that not having to do this 80% of the time was a monumental improvement just it's interesting to me counter intuitive because it gives you a feel for human expectations of what they're expecting out of the technology versus status quo and what it was. And how that alone starts to drive different different areas of adoption experience and enthusiasm around a lot of the technologies that individuals are going to be. Engaging with over the next five to ten years. Awesome won't won't be boring. Yes, we have some interesting times ahead. So gentlemen, it has been a pleasure. You know, going through this exercise and talking about kind of where what we're trends we have seen where the future is headed. And I want to encourage the audience actually to do two things. One is you know, you'll see a QR code two QR codes here on the slide. You know, the first one is actually linked to the Deloitte I study reports that we talked about. The second one is actually to the landing page where it's going to vote Deloitte and data to we're talking about how we're helping you know our clients. And as we wrap this up, one final closing point, you know, both from Ben and Dave, you know, as key takeaways to our audience of what they should be looking for next. Ben, you want to start with it? Yeah, I think key takeaways. I was on a panel yesterday and someone asked is is AI going to take away our jobs and and some people can be scared of that. And I think the thing I've seen applied in the mystery is if you add AI to a process, you haven't even turned on automation. The moment you add it to a process, the process could evolve subject matter experts will suddenly be challenged. They'll be thinking about new ideas. And I think that's the biggest AI is a gift to a business. The biggest gift you get is it changes the culture to an innovative culture where people are no longer bored. Your senior employees are not bored going into work tomorrow. For a process owner that's 20 years in, they know how to do their job tomorrow. You introduce AI. Now they're innovating. They're creating. It's so very exciting times. I would urge the audience that this is not the time to wait and see. When it comes to AI, we are definitely at an inflection point. You I travel around the world selling AI systems to every industry you can imagine. And the value is there. It's real and definitely reach out to us and the partners. We have that we've paid that tuition, right, David? You got it. I mean, I know if I was going to file into what Ben said, some of the I take away is I guess for a second. Remember incremental leads to transformational across many different areas. Focus on adoption in that last mile. We talked about don't underestimate the impact of actual use of the solution in the in the organization. And a latent outcome related to a lot of the most successful organizations that we've seen is underlying collaboration across the organization to bring some of the most exciting. Use cases develop requires talent from across your organization, be it the business technology, different areas. And I'd say that's what many organizations are unexpectedly surprised with of how it's driving better teaming because of what's required to be successful in space. Awesome. With that note, thank you, gentlemen. And thank you to our audience for staying with us to this event. And hopefully you'll glean some information about where you are in the AI journey and how good the Lloyd and did I could help you take that next step. Thanks, everyone for your time. Thanks enough. Yeah, thank you. That was fun.