 All right, I would like to welcome up, Darren Brown, Solutions Engineer here at Data Iq, and Jason Morenda, a Sales Engineering Manager at Snowflake, and they're going to talk about some of what it looks like to use Snowflake and Data Iq together. Are you all here? All right. I'm going to stand because I wander. Okay. You were welcome to sit, but I'm a wanderer and I'm a pointer-outer, so I am definitely going to stand. And I also talk with my hands because half of my family is Sicilian, so just how it is. Thanks, everybody, for having us in. Thank you to the Data Iq team. We love working with you all, but thank you for the warm invitation. And this is definitely a better together relationship. It's not, you know, for you people in the room that use Snowflake or know a little bit about it, we do a few things and we do them very, very well. But we let you bring your best of breed technologies, and that's really what we look at with Data Iq. There are things in there that are going to be fundamentally topics that they are always going to address. We're not in, Snowflake is not in that space. We are about reducing data friction and data movement and things like that. But at the end of the day, Data Iq, that is not my slide. Where'd we go here? Oh, somebody went. Thank you, or a family that's not sliding hard. Thank you for going backwards. You got to go. Oh, help me. There you go. Okay. No, go to the next one. There we go. Okay. That's what I'm sitting. Okay. Sorry. I got a little thrown off there. That's not kept up yet. Okay. Cool. So like I said, we do a few things very, very well. And that's our goal. We are not going to be your be all end all for your data environment. We talk about taking whatever data that you have, the traditional structure data, unstructured data, and now your, excuse me, your traditional relational data, your structure data, your semi-structured data, and now your unstructured data. So what does that mean? Structured data is what you think of it. There's in columns of data that's been in a database for decades, right? Snowflake was the first new MPP database that was built from scratch in the last 35 years. If you want more on that, come see me afterwards. I'll give you the whole background on it. It's fun. So my structured data is that data that's being produced by all of these modern systems. JSON data, parquet data, Avro, and Ork and things like that. XML, we're seeing less and less of that. And then your unstructured data is your data that's images and files and documents and all this stuff that's living out there that you're trying to break into the next phase of gathering intelligence out of. Right? So like the data IQ team, right? Being able to take advanced analytics and apply that on a set of data that you've never had access to, whether that's images, PDF files, things like that. That's all part of where we come into taking this data that's historically been very difficult to get into. Now, at the end of the day, we're about delivering outcomes, right? These outcomes that you see over there on the right hand side are why people do technology. You have to have a problem that you're trying to solve. Right? That problem can be in my out of inventory in a particular area. What's the right customer for me to target? Right? That's the outcomes that we're looking for. All of this stuff that we do here in the middle is really based around what we do with the technology and delivering the promise and the elasticity of the cloud. What Snowflake did was essentially reduce the friction for getting data into your end user consumers' hands and doing it very, very quickly and very, very easily. You'll see some things across the top. This is our marketing slide. This is the way we talk about all of the workloads that we have, whether they're data engineering or cybersecurity. All of those are fundamental to what we do on the platform for data warehousing and the data lake or the lake house or whatever you'd like to have it called. But at the end of the day, people use our technology to do things. Those things are across the top. They use the underlying elasticity of the cloud to do that. This is not our marketing. What our customers are doing with it. What our customers do with the snowflake is what we are using and describe that with those tiles across the top. Now, everybody has seen the slide in one form or another. This data silo thing has been a problem for the last 30 years. It's always been the case because whether we're talking about a cloud infrastructure where somebody took an on-prem technology and put it in a VM and they drop it in the cloud and say, now we're in the cloud, that still is a data silo. Because you have this limited amount of disk and limited amount of compute that you can use with that. And at the end of the day, you still have a data silo and all you've done is moved that to the cloud. Snowflake addressed that by giving you essentially limitless storage and limitless compute. You're frankly, your only limit is your budget that you would like to spend. Now, that's not always an attractive thing either. People do have budgets and you've got to maintain budgets. Our CEO Frank Sluitman talks about unleashing pent up demand. And that's what Snowflake does because we don't have this idea of data silos goes away because what we have done is essentially mobilize all of our customers data. And that mobilization of that data looks like this. So this is not a made up slide. One thing about being a data company is we measure and know exactly how our customers are using the platform. We are data blind, but we have to know where our customers are using it. We have to know what regions they're in. Are they talking with each other? So all of these little clusters around here, this is a data provider that is sharing data with all of these different dots around there. The big one when this came out, this is the data cloud today. It's actually about a quarter ago. So you're going to, if you went out and looked at our most recent earnings release, that's going to be a denser graph at this point. So what it looks like though when you start talking about particular industries is if you are a retailer, right? So across the CPG environment, if you are a retailer, if you're low or you're urban outfitters, you want to know where is your stock? Do I have a weather event in a particular region that I need to take action upon and source items from a different area? If you've had to do that in the past and you've had to go out and get third party data, right? This is a data science user group and presentation. Part of the most difficult things you guys have to do as data scientist is finding that data and getting it and making it useful for you. Where Snowflake does this, right? We interconnect these dots and allow you to do this in seconds. We take a six week project where you would have to go find the data, contract the data, do a project with it, and then finally have infrastructure to land it in and then get it into people's hands. Right? That's, don't ask me, ask what do you know yourselves if you had to contract a new data source? What is that? Four weeks, six weeks to do something like that? You can do that in 30 seconds in Snowflake. The reason we did that is essentially if you want to know what this gives us an analogy, we are doing to the data ecosystem, what Netflix did to blockbuster. Right? That's our goal is to reduce all of that friction of data movement and data silos and getting it and making it very accessible in your Snowflake account. You do have to be a Snowflake customer. That is part of it, right? Of course. Now, how do we do it? You know, on the right hand side you'll see the ways that we do it. We talk about direct shares, right? That's sharing directly between two third party organizations. You're on Snowflake, they're on Snowflake, you create the share away we go. We can also do something called a reader account, which is if you have somebody that you're sharing data with who's not on Snowflake, you just want to give them access to the data, being control of it yourselves, you give them a reader account and away you go. The last one is a data exchange, and I'll loop that in with the data marketplace. So the data exchange is essentially a private data marketplace. It's between companies that have agreements or organizations that have agreements. The data marketplace is essentially Spotify or iTunes or the App Store for data providers and data consumers. There's 1700 plus data sets that are out there today. There's 300, 400 different data providers that are out there and many of them are free. So if you want to know, if you want to see free ones and you don't have a Snowflake account, come talk to me, talk to Daniel or talk to John in the back of the room. We'll be happy to show you where they are. If you don't, go out and sign up for a Snowflake trial account, right? They give you $400 and 30 days to test it out. You can go in and look at the marketplace and see the data and get access to it through that. It's a full use account. So this marketplace is one of my most fun things for me to talk about. Because there is data from weather, finance, data from the largest financial services providers out there, all the way down to people whose business is data. One of my favorite ones is a company called Safe Graph. All they do is location analytics. So if you've got a data set and you know where your customers live and you'd like to know where they're going with foot traffic, Safe Graph has got a data set that's out there that you can do that with. You can literally look at what are the high traffic Starbucks locations and where are your customers based on their mobile identification number. So some really interesting data sets that are on the marketplace. And you go out there, you click a tile and if it's free, you click on Git. And then that much time, it's inside of your Snowflake account accessible. Now the benefit here is that's not an extract of data. You're not paying to store it. All you're doing is providing access to that data set. So the benefit there is that your data pipelines are always up to date. There's no extracts, no security of sticking in a bucket or an email or a CSV file that people are dropping out there. It's just instantly available. So for data scientists and for people that are actually going that next step in their journey, you start talking to a data scientist. You don't talk to Darren. He's a practitioner. How much of your time are you spend day or wrangling and data prepping and finding all these different data sets and then you've got a provision infrastructure to do that. That's not fun. Data science, it's a very sexy, selling job. But if you called you data wranglers, people probably wouldn't put that on their LinkedIn profile. So what are we doing about with that? We're enabling our partners to take that code the way that they would like to code. And I call our partners the data I choose in the world. Our partners and our customers are also the same way. They want to do things in Python. They want to do it in Java or Scala. They want to take that language that they know. And most importantly that their people know. The hard it, they ask me when new customers ask me what's the hardest thing about snowflake? The first thing is is your data in the cloud. Because if it's not, it's the hardest first step. Getting your data to the cloud involves security includes info sec. It includes do you have an ETL tool that can connect to the cloud? It's easy as that sound. Maybe you want to stand up and I, you know, a data I could trial and move that data along, right? That's very easy sounding but talk to, you know, I've got a customer right here. Talk to them. That first step to the cloud is the biggest step. After that, it's very easy. So the second hardest thing is using the skills that you have. So if you've got a team that knows SQL, awesome. You know snowflake. If you've got a team that knows Python or Java or Scala, you've got team that are ready to go. So you code in the language that you would like. You bring it on to the platform and start doing your, you know, your analytics and your data processing from there. So I talk fast. I've got two other people here from snowflake with me as well. If you guys have questions, you know, I'll be happy to answer them. We're going to be around all day. I'm going to turn it over to Darren because he's going to talk about a couple of items that are really kind of very interesting in terms of. Oh, here you go. You're good. Okay. Cool. All right. Thanks Jason. Yeah. All right. So now that you guys have been introduced to snowflake, you know, we have been pretty good partners, right? Snowflake considers us their technology partner and data science two years in the row. That's pretty good. And since we're here in Miami, I want to talk about like why are partnerships important? And you know, here we've got detective sunny cricket and I had that jacket and it's great. Right. Went to my middle school dance almost exactly dressing. I think I did as well. And then we've got a Dwayne Wade Miami Heat, right? Fantastic in their own areas, right? He solved lots of crimes. He played some pretty good basketball, even one in championship by himself. But when you bring in a really good partner, right? You get Ricardo Tubbs, you get LeBron James. The outcomes are incredible, right? The heat one, what? Two back, you know, one two championships back to back went four times. Amazing, right? And obviously the Miami vice here, they brought down the biggest criminals in the local area. So. So what all that being said, like, you know, we think the two, the two products represent your best and breed machine learning stack is Jason said, you know, we're going to bring all your data. We're going to use the language that you like to use in an integrated ecosystem to build data science or data products. Right. So let's kind of run through some of these integration points. Like Jason mentioned already, if you know SQL, you know snowflakes. So like data could helps you, you know, do SQL. If you can write SQL code, you can write in data, could data could push us that compute down the snowflake. That's the easiest and most obvious integration point. But another thing that data could one of the secret sauces that we bring is, you know, kind of what our visual recipes where maybe you're not that great at SQL, right? You can use our visual recipes to do data wrangling activities that get converted to SQL and push down to snowflake. So. And then we've got Java user defined functions or UDFs. So where SQL can't do some stuff. You need like a little more custom approach to manipulating your data or scoring your models. You can either write UDS with code or again, we have visual tools that do it for you kind of in the background, push that UDF down to snowflake and the compute happens seamlessly. Jason kind of hinted towards snow park for Python, writing that code. Again, this this is truly kind of a game changer now because we're now really able to meet our users kind of where they're at in terms of if they want to use Python to do their machine learning or their data wrangling all the way down to the machine scoring. I think a snow park really kind of enables that sort of capability and of course data to can orchestrate and manage your elastic compute resources with spark. And so we integrate with snowflake spark connect to seamlessly connect and access snowflake tables without really moving the data at all. So those are those integration points and then you know this slides a bit busy, but we're going to kind of walk through it to show those integration points kind of an action. And the main takeaway here though is that integrated ecosystem that we mentioned earlier where with the two products you can kind of go from data ingestion where we're reading in your data into snowflake to your point get it into the cloud. And there's some integration points to make that happen pretty seamlessly and then we've got our data wrangling feature engineering where again we in it we believe we enable users of different skill sets whether the writing code or using our visual recipes to do do their data perhaps feature engineering going over to machine learning training model experimentation. And then once you finally have that model to deploy that model in a variety of ways whether that's I'm going to do batch scoring I'm going to generate an API I'm going to build a web app whatever it's going to be between the two you know we kind of handle that whole in in of a of an analytic project. So to wrap it up because I'm keeping you guys from what smells to be a pretty good lunch. I think you know you guys can read the slide I think at the end of the day we feel like we enable more people to access the data and work with that data faster to deliver things faster so it takes to shorten that time to value right. And the kind of way we do that is again blessed best and brief solutions that support for different languages or whatever the skill set of the user or their preferred sort of language of choice. Data IQ orchestrating your your snowflake resources or spark resources managing the compute pushing that compute down and then ultimately providing like a governance layer I think Jad talked about this in the version 11. A governance layer on top of all of these activities so that these things can be repeatable transferable and things like that so I'm done. If you have any questions you can find me I'll be around and I think we gave you some time back all right all right. All right. Thank you very much. All right. All right. Well guess what now it's everybody's favorite day we're going to take a break for lunch. So as I mentioned before this morning when we come back from lunch we're going to switch into doing some of the hands on sessions so there's hands on labs there's instructions in the emails that you should have received. We're also going to put them up here on stage so that it'll flash through so you can go ahead and do it so please take a chance to do that at some point over lunch. But thank you all for your engagement this morning it's been a great morning session will take a break until 130 for those of you on the live stream. I also encourage you if you're going to be planning to do the hands on lab get the stuff set up earlier especially since you won't have tech support walking in the around in the room to help you but if you need anything we will be walking around to help. So everybody have a great lunch it's off to the left here and we'll see you back here at 130.