 Hello everyone, I know we are right before the insects. I can see a lot of people already going there. We're going to try to make this very engaging and efficient for everyone here. I'm here today on behalf of the ocean clean up. We are a nonprofit based in the Netherlands whose mission, which is very ambitious, is to get the world rid of ocean plastic pollution. And more specifically, we want to get 90% of the plastic out of the ocean. Just last week, we just reached a huge milestone, which is our scenes in the North Pacific Ocean, just right west of here, have reached a milestone of 200 tons of plastic extracted from there. And we make a lot of things out of them, including these sunglasses, for example, and a lot of other products that we sell to fund the clean up. But there's a lot of data people here, so let's talk about data. This is a five million tons problem. There's five million tons of plastic that get in the ocean every year. And there's a lot of things that happen to it. It doesn't always go straight inside of the needle of the ocean. Sometimes it stays on the shore. Sometimes it sinks. Sometimes it goes in the ocean and sometimes it goes back on the shore and back and forth. So how do you solve this? We have two technologies that we try to do this. One is in the river, so we catch the plastic before it reaches the ocean. And the other one is in the ocean where we get the plastic that's there because it's not going anywhere. We need to clean it. But today, I'm here to talk about something else. It's a project that we are doing with what's on the shore, more specifically talking about beach cleanups. So why are we interested in this first? Because what we are doing at the ocean cleanups are modeling capabilities, allow us to model what's going on with plastic all around the world. And what's going on on the beach allows us to calibrate and improve our models. But also because as data people, we're interested in measuring the cost efficiency of what we're doing in the ocean compared to what's going on by simply cleaning what's on the shore. It's also important to realize that because we have these modeling capabilities, we can help the people that are cleaning the beaches. And the last thing is what exactly is our impact on the plastic that arrives on the beaches? If we measure this efficiently, we can better understand what is our own impact on the environment. So maybe just for the sake of definition, what is a beach cleanup? Pretty straightforward, pretty sure. But basically, it's people gathering together to protect their environment. Sometimes it's organized, sometimes it's spontaneous. Usually when it's organized, you'll have an NGO, so big on our organization, or more local ones like citizen gathering together, or even students just saying, let's clean this place. And sometimes it's more spontaneous and that happens way more than we might think. People going to get this on the beach and being like, oh, there's plastic here. What do I do with it? And so that's a lot of different people that are participating in this efforts all around the world. And that's a lot of data. And so if we want to do something out of this, we have to realize that there's a lot of different places to get this data from. When it's about organizations, there's already a lot of people doing this. Some of them are very organized. You'll have like a million volunteers, and they all collect the data about what they clean, so you know what plastic, how much do we collect, all these kind of things. So it's easy for us to work with this data. And then you have smaller organizations that do not necessarily collect the data in a consistent way. And sometimes they are just very localized. So if you want to get data from everywhere around the world, it's a nightmare. It takes months to send emails to people who are in different countries everywhere. Get them to answer, get them to send us their data. And sometimes they are not even being paid for this. Sometimes they just have these little CSV with like three roads, and you have to concentrate all of this in one place. And that's only one part of the problem. Once you have this, you also have the other aspect which is getting the data from the people who do this continuously. And fortunately for us, they do something that's really cool, which is going on the beach, taking some few kilograms of plastic away, and then taking itself, doing like, look at me, I took 10 kilograms of plastic out of there, which is funny, but at the same time very useful. And we really like that. And if you actually want to do this yourself, that helps us. So please use social networks. And if you concentrate all of this data, that's actually a lot of things that we can do with it. And so we centralize all of this. And we have already a lot on this. So the object of the project that I'm talking about today are building this database, creating some analysis and interpretation out of this, and also using them to improve our own cleanup strategies all around the world. So let's develop a bit much into the technical details. Let's be quick. When it's structured data, we can use a lot of software that we have to just consistently reformat them. So for example, the software of data, who is really helpful for this, all these CSVs, just all in one place, make sure that the rose columns are properly formatted. And we get a huge database with localization of each bit's cleanup, the weight of plastic that was taken, the types of plastic that was taken. And so that's the easy part. When it's from social media, well, we are using something that we all know now, our new Laurence Azure chat GPT. And that's a project that has been done in collaboration with Stanford University and actually the students who have been working on this project right here in the audience. And so what they did is train an NLP model to get from captions of photos on Instagram, the amount of plastic, the type and the location and the organization that did that. So to do this, to be very brief, you use chat GPT to create a lot of labels of type of plastic and weights, create fake Instagram captions, and then you train a model on it to be able to predict back from like real data from Instagram. To be very simple about this, it's a fully neural network model that they customized by adding a bit more of transform layers in there, reaching a pretty good efficiency of a F1 score of 94%. So basically, it's quite good. And if we use this on Instagram data, the efficiency is slightly lower, but it's still pretty good. And that allows us to do something which is super cool, which is augment our own database. Right now, by working with more than 15 organizations around the world, we already have in Data Science Studio more than 800,000 rows of plasticina data. And with this, we could easily double this, maybe even more, by just getting collecting data from social networks. Now, what do we do with this? Many things. One example of a simple analysis is determining hotspots of plastic pollution all around the world. If you get the length of a coastline and you define a hotspot metric, which is the plastic density in this case, you just take the bitch clean up data divided by the length of the coastline and you can build a global density map of all the places that are extremely polluted around the world and in which people are cleaning. And so that's great because we can use this for ourselves, but also to help other people who are cleaning bitches all around the world. And so that's good for everyone, but we also have another kind of thing that we can do with this, which helps us directly, which is optimizing our models. So this is where I talk a bit more about like the rest of the work that we are doing at the ocean clean up, but basically we have this forecast of plastic pollution, which is kind of like a weather forecast where instead of like predicting the rain or the wind, we predict a wave of plastic and where it goes in the ocean. And this model tells us in particular where the if the plastic is going to arrive on the beach. So if I tell you I'm supposed to observe a wave of plastic on this beach one day and you tell me because you have the database, oh, this is actually not what we observe, we can recalibrate. And this model helps us do the rest of the work that we do, which is cleaning up off shore. So by just recalibrating and using this big database, we can improve the efficiency of all the other clean up efforts that we have. So this is just a big chart of what we're doing, calibrate with the beach clean up data and then optimize the clean up operations with this kind of map of all the places we have data. So in conclusion, in summary, this project is what's about building the world's biggest database about beach clean up data, which we have already not a lot on this. We have already started analyzing it and using it for improving our own operations of clean up. And so this is a great example of how data centers can be used for social impacts, and environmental impacts. Personally, it feels really, really great to be able to work on this, not just because of the kind of project, but also because of all the people we're working with. And so this is the moment I take to just acknowledge all of the people who have been helping us on this because there's a lot of people. All my colleagues and former colleagues at the ocean clean up, obviously data, the EKIGY program, they allow us to use their software, but also get counseling in data, Stanford University, via the EXPOP program and the students who work with this, and all the organizations around the world who have been sending us their data and collaborating with us. And finally, you, for listening to me, and so enjoy your lunch, and thank you for listening.