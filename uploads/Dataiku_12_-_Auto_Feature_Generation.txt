 When engineering features for a machine learning model, it can be time consuming and error prone to painstakingly construct dozens or even hundreds of computed features by hand. ADIQ's Auto Feature Generation makes it easy to discover and generate many new features from your existing datasets in just one step. Let's say we're an airport operator working on a model to predict flight delays. We have a dataset containing flight delay information for one month, but it only contains a few columns. We want to enrich this dataset with other attributes like root details and more delay records from previous months. We'll start by applying the Generate Features Recipe to our primary dataset. As always, we'll first name our output dataset. The next step is to configure the relationships between this table and any enrichment datasets. Let's add the root details dataset to the recipe. In a moment, we'll come back and discuss what these settings for cutoff time and time index mean. For now, let's click Save. We're prompted to select the relationship between these tables. Since you can have many instances of a delay for a single flight route, we'll choose a relationship of many to one. We'll keep the suggested join key of root name. Next, we'll enrich the root details dataset with the third dataset containing more historical delays. Here, the relationship is one to many. Since each unique root from the root details table, corresponds to many rows in the flight delay's history dataset. Note that when you select a one-to-many relationship, the join key will be used as a group key for aggregations later on. If you want to filter time ranges in your enrichment datasets, either to avoid prediction leakage or just to set up time windows, you'll start by configuring a cutoff time on your primary dataset. The cutoff time indicates the last point in time that data from enrichment datasets can be used. We will select the flight date column as a cutoff time. Since we don't want to join rows from enrichment datasets that took place after this flight date. If your enrichment datasets have a notion of time, you can configure time indices to exclude all rows that took place at or after the cutoff time. Now, you can also optionally configure time windows to further constrain the time frame of the rows to be included in a calculation or aggregation. In our example, we want to include flights in the 30 days leading up to the cutoff point, but exclude any data occurring after that point when building features. Since including that information could cause data leakage in our prediction model. Let's next select the columns we want to generate new features from. Now, we can choose the types of transformations we want data IQ to automatically perform. These are suggested for us by type, and this saves us the added step of using a prepare recipe beforehand to perform these calculations or transformations. As we select columns and transformations, notice down here we have a dynamic counter of the number of new features that will be generated so we can estimate the size of the output dataset. For instance, for parsed dates, we may want to extract date parts. While for categorical variables, we may want counts for each distinct class value. For numerical variables, we can choose aggregations similar to those we find in a group recipe, and for text-based columns, we can derive features like character count and word count. This recipe works with SQL datasets. As with other SQL-based recipes, it's simple to view the query being generated behind the scenes, and to convert this to a code recipe if you'd like to modify it programmatically. Once run, in the output, we see that with this single recipe, many new features were automatically generated for us. We can see all of the new columns quickly using the columns view or the quick column stats. For the newly generated features, notice the automatic description field that gives users more context. We can explore the descriptions and bulk by visiting the scheme of view in settings. Zooming out, we can see the new additions to our flow, and use this enriched dataset to train a machine learning model or perform other data analyses. For improved efficiency and a reliable, systematic way to perform feature engineering, try out auto-feature generation in your own projects.