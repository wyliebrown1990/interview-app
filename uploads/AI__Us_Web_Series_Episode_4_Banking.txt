 A merchant lends a farmer some grain and a few months later, when the harvest time comes, the merchant is paid back in full from the proceeds. This evolved into the exchanging of goods and the storage of valuables all run out of the temples and palaces of great empires. And so banks were born. Well nowadays the banks themselves are the empires touching every facet of our lives and every corner of the globe. But are they the cutting edge of tech too? Are they using their immense resources to push the boundaries of artificial intelligence? Before we find out, here's a few facts about finance, AI and the relationship between the two. Banks really started utilizing AI in the 1980s to predict market trends and provide customized financial plans for their clients. At the same time, more than two-thirds of Fortune 1000 companies already had at least one AI project under development. By 1993, AI was being used to detect fraud, uncovering almost $1 billion worth of money ordering cases in two years. And as of 2020, 52% of financial service providers had implemented AI-based products and processes because it's a gold mine. This estimated AI technologies could deliver an extra $1 trillion each year for the industry. Finance and AI are match made in heaven. All those ones and zeros to go with all those dollars and cents. Or is banking one of the most heavily regulated industries on earth? Going to make slower going with AI than first thought? We investigated how AI and finance continue to evolve together. What efficient intelligence is beginning to affect how we begin to solve business problems? It sees patterns in information that we just can't imagine, but the computer is able to detect these kind of hidden patterns and the information that we can't see. What we're seeing is very, very specific, scourable tasks being augmented often very effectively. What we are not seeing is the removal of a person entirely from a fundamental decision. The banking industry has used models for a very long time and we're very aware of how to in some way manage it, not to say that there's no risk associated with them. As an industry, we are very prepared to use models. Bank has had a digital strategy to use data, a new technology to help the banks manage its financial performance and make strategic decisions. So my job is to help the bank make that leap at that scale. It's not just bringing together that information, but how do we start to really use the intelligence of the computer system itself? So the computers are able to do things that we would normally associate with human intelligence. There are certain areas in which AI still doesn't exist, if any applied or practical sense. In other words, you could probably go back a decade or two for the very first messages of it being implemented. We've gone through a change of the last couple of years where we can harness big data. AI allows to make those series of logical deductions. It has enough understanding if you trust it of your financial behaviour, it understands your financial position. Even today, we model our corporate planning process, is part of that model by the movements of interest rates and the movements of all of FX. But it will become more dynamic and it will change as AI becomes less of a modeling task. But something that reflects basically the forward-looking financial view of the bank. The end result that I would imagine we'll see in the coming decades is just more and more augmentation. More and more we will be seeing AI being used to assist human decision making. But I very much would expect to see a lot of human still in the loop. We have the advantage that financial services is no stranger to using analytics of any kind, statistics, clustering, segmentation of clients in a ways that have caused severe problems. That's not a new phenomenon. It's one that's very well understood in principle and it's something that people do look out for quite rightly. And there's a regulatory apparatus that's been built up over a hundred years to corral that and to contain it. But finance is much more around products and countries, accounts and customers' behaviours. Certainly, some of the most valuable areas in banking in terms of where optimization, efficiency, and so on could be most valuable to the actual bank's bottom line, or also the most heavily regulated parts of things that are controlling the actual issuance and risks associated with credit, for example. That's the area that the bank could potentially make massive improvements in terms of their bottom line, but it's also the area that's most under the scrutiny of the regulators. The areas that are at least under the areas of regulatory scrutiny are things like customer interactions, at the very basic level when you've already un-bored the client. It still can lead to bad decisions. It can still lead to excessive risk taking. AI will not stop those occurring. It makes it less subjective as in it's the gut telling us to do it, but more driven by a sense of being able to master our past to be able to better manage our future. By analysing vast amounts of data and the blink of an eye, and with their ability to detect things like fraud and money laundering, could AI systems have predicted or even prevented the major banking crises of the recent past? Should AI move beyond chatbots and become a dispassionate regulator of our finances? I hosted a roundtable to discuss what could happen if we let AI run wild with our money. So I'm really interested. Do you think today's AI technology could have predicted the financial crisis of 2007-2008? Give me a one word answer to begin with. How about you, Carl? No. Bonny? No. And you're saying, are you going to... Yes. OK. Tell us more about why. To do AI, you need the data and you need models. And truth is, there we are both. The AI tools are fine, but I also think there were weaknesses that were apparent due to human behaviour, institutional weaknesses, and policy weaknesses as well. People did predict that there was a crisis on the horizon, and some people made a lot of money from it. Let's just say that we did have the tools in place to predict that sick credit default swaps would cause the damage that they did. OK, we still needed to know to look for it. AI is great at learning from historical data, what the next prediction could be. But if you have instances like it happened in recent time, where you have major changes in how the world operates, say, like COVID, then that relationship changes, and it's difficult for the model to understand how that relationship has changed and adjust its predictions accordingly. You can't just ask a model to completely change task and solve a different problem. I think that it's still a blunt tool. When capable investors or economists were able to predict some of those crises, it's because they had a complete world model in their mind. So what I expect we will work on more and more going forward is to give AI in one or two generations a proper inferential power, which comes from having an ability to understand the environment and adjust the data. Bonnie, do you see much appetite from regulators to adopt AI? Either as a means of greater oversight of banks, or as a way to stop their own regulatory blind spots. I think many regulators around the world right now have been making great strides in that direction already. And if you actually look at financial crises throughout history, most of our regulation in place tends to be reactive rather than preventative. Bank of England in 1694 comes out of a financial crisis. I don't think we'll ever be able to prevent financial crises outright. But I think what we can hope to achieve is to at least minimise the economic and social damages. Given the data intensity of finance, many might have expected that it would be further along adopting AI at this point. We've talked a lot about how regulation might constrain the adoption, but what else might be holding things back beyond regulation? There are thousands of millions of use cases that AI could be applied to. The cutting edge of AI is being applied, but there are going to be instances where adoption is going to be slower. Until we're able to build up that trust in certain key areas, I think AI is going to struggle to be adopted to the full capabilities it can. You know, don't get me wrong. I do believe that artificial intelligence deep learning, machine learning all has tremendous promise for improving the credibility of regulation and policy evaluation. But the main challenge we face right now is that the rate of, or the pace of change in artificial intelligence methodology, tools and techniques, that rate of growth is really outstripping the current legal and regulatory framework. Maybe things will change 20 years from now, but again, I think that's the other thing that's holding us back right now, the trust and the algorithm. Think about today. Think about 20 years time. You're in the Fed Tech space. What's the biggest financial decision that you would currently trust in AI with today? I think I'm on the early side, on the early adopter side. So I'm probably the person who today would feel more comfortable yielding investing decisions to today. I, it's not unfettered. It's not a blank check. But it's enough to begin on the road to automation. So are you optimistic about the future of AI and financial services? And how far off are you from handing over those life savings to a machine? Well, I'm very optimistic about the future of AI and financial services. And in fact, they already have given the machine authority of my teammates over at my investments. I'm absolutely positive about the future of AI in financial services. And as long as the trust and explainability is there, Sean, I'm not far off in trusting my savings to AI. Yeah, I'm optimistic. I think there's so much data out there, which is key to any development of AI solutions. They'll take the banks a while to adjust to what AI can do. But I think it becomes more robust, trust will improve. And people will start to see it in all areas of banking. So banks with quite literally all the money in the world aren't quite the AI pioneers you might expect. Is it because they're already as optimized as they can be? Or maybe it's that our money is the one thing in life we're reluctant to hand over to machines. But how long will it last? Is it safe to assume that eventually our currencies and savings will be regulated and guarded entirely by AI systems? Until there's a dramatic change in the landscape, personally, I wouldn't bank home.