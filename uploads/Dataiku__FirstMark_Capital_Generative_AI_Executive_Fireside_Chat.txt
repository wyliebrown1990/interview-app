 Hi, I'm Florian Dweto and CEO and co-founder of Dataku, that take with Enterprise AI platform, leading the world in terms of making AI more easily leveraged by large enterprise across the world. And I have today with me Clemon and Matt to discuss chat GPT, or I would say more large language models and generative AI. Hi, Clemon and Matt, would you introduce yourselves to start with Clemon? Hi, my name is Clemon Stenak and I'm Chief Technical Officer and co-founder of Dataku. And I, my name is Matt Turg, I'm an early stage venture investor at FirstMark, which is a firm based in New York and I am a very proud investor and board member at Dataku. So everyone is talking about chat GPT and generative AI these days, but a lot of stones are left and term on that front. And I think all audience has lots of questions on this topic that hopefully we can discuss and so on today. And so maybe to start with a fairly technical one, but I think that everyone is hearing about, it could be for Clemon. We've got lots of terms that play right now related to generative AI. Chat GPT, GPT3, GPT4, GPT3.5, LLMs, Bards, Burt, Londar, and so forth. So what does it mean like Clemon, can you help us with a quick disambiguation? Sure. So that whole field actually started between 2015-2018. And then this is the field of what are called large language models or LLMs. The core idea of these models, so they are machine learning models that have been trained to predict next words in text. So the idea is that during the training process, the model has been shown immense quantities of existing text from the web, from questions and answers website, from code, etc. And basically has been trained and rewarded for correctly predicting what will be the next words in text. And the sheer size of these models and the sheer amount of data it has seen makes it so that then it becomes able without actually fully understanding what it's doing, it's able to produce statistically extremely probable text and the fact that what arrives is that these models are able to create new text and especially when asked to do something. These models are then further refined by having humans vote on the output of models and sheeding that back into the model in order to improve the model. And again, this started a few years ago and there were a subpart of these models are called GPT models. So it's really GPT is a family of models. There was GPT one, GPT two, GPT three that were built by a company called OpenAI. And then there was a lot of replication of these models in the open source community. And what everybody has heard of, chat GPT is actually a refinement of a model called GPT three that made it very able at doing this question and answer this very chat interface. Again, we are seeing a lot of other attempts. So you have Google who is creating a garden, exactly like chat GPT. You have the new models called Lama from Facebook which are again, variants of it. So there is really this idea of platinum with models that can create new texts that can basically follow instructions and you have a ton of variants of them. And so of course, a field that is moving so fast that new turns, new names appear on a weekly basis. Yeah, great. We've got new names every day or every week and machines are generating garbage that is getting filtered by humans. So it's a very dystopian view. But I think that we also hear about lots of use cases of such technologies in the enterprise. So for both of you actually, what do you think of the top three use cases for the enterprise for those technologies? Yeah, so I think it's all a very new field. I think everybody is trying to figure it out at the same time. I think it's one of those very exciting moments in technology when the pace of acceleration of technology is actually taking everybody a little bit by surprise, both in terms of what to do with it, but also had to make sense of it at an almost like a society in human level. So it's a little bit of a giant experimentation that everybody is going through right now. I think it's particularly exciting about generative AI as opposed to other waves of hype in technology is that there are a bunch of fairly obvious applications both at the consumer level and the enterprise level. If you think of the fundamental thing that all those models do is really create content and enable people to access content in different ways. So everywhere where there is content both at the consumer level and in the enterprise, you're going to find interesting applications of generative AI. One super obvious application of it in the enterprise is around code and code generation. If you believe that every company is becoming a software company, every company is becoming a data company. In the AI company, we are actually in a world where we probably have not enough code as opposed to too much code. There is a bottleneck around the number of engineers and data scientists that you have in the world. I think generative AI offers an incredible opportunity to enable all sorts of people that may not have fundamental training in computer science to help create code. As we know, generative AI has a tendency to make up stuff what's known as hallucination. So it's not at a stage yet where it's going to be able to create perfect code every single time. But it is at a stage where it can help you get 80% of the way and do a lot of the grunt work and you as a coder, as a developer, can then correct whatever came out of the generative AI model in a way that will just completely accelerate your productivity. So coding is one example. But all the other parts of the enterprise where you have content, which is pretty much everything, you can have an opportunity to use generative AI as a co-pilot to help you being more productive and create both stuff better faster. So you can think of it as marketing material, so you can think of it as sales enablements, you can think of it as internal communication and so on and so forth. Every part of the enterprise wherever content is involved from video to a simple email or a Slack message can be dramatically improved with generative AI. As a software engineering leader, the code part indeed resonates a lot. And it's really interesting and it's here that there is really distinguishing the noise from the reality is difficult because it is incredibly good at reproducing common stuff. So indeed, when you ask it to do coding tasks that are quite generic. So for example, starting an application, it will work incredibly well. It will work scarily well to be honest, you could say, okay, are software engineers doomed. There is still a long way to go there, but I fully agree with that idea of seeing generative AI not as something that will provide the code, not as something that will replace, but really as an assistant as a productivity and answer. And we've started the the decor and the making a few experiments there are still a lot of questions around reliability around legal aspects, etc. But this assistant aspect is indeed very interesting. There are a lot of traditional in a way tasks in natural language processing that can suddenly become much faster and much better. It is very common to have a lot of content. For example, you have a product and you get user reviews and you want to identify the core trends, the core topics in your reviews. This is not something new. This is a field that has existed for probably 20 or even 30 years. But the recent advances in not just generative AI but large language models in general have made these much faster, much more precise and importantly requiring much less manual input. It used to be the case that you need to have tons of either highly specialized people or tons of data that gets manually labeled. The real revolution of these models, you may hear it referred to as few short learning, is that again, it has accumulated so much, quote, knowledge that it can very, very quickly generalize. Meaning that it only needs a few examples of what you want to accomplish to understand what you want to do. Typically extracting root causes from incident reports, extracting ketopics from product reviews becomes incredibly faster. So you mean, for instance, if I'm a big consumer good or retail company, and that I would want to extract key topics from customer reviews in order to find the best next actions or accelerate processing of complaints. Building for choose cases would take, I don't know, 100 days or 1000 days before and that was generative AI. It takes what 10 minutes, one hour, 10 hours. How much is, would you quantify the acceleration? It's difficult. The thing is that, and that's a danger actually, you can get an answer in 10 minutes. That's for sure. But that's again, probably more of a danger because one of the facts of generative AI and it's related to what Matt mentioned about hallucination is that it will always have an answer for you. But very often that first level of answer will either be very unsightful or very wrong. So you still need, and you may, er, refer to as prompt engineering, you need to fine tune how you will ask your question, the AI is still very sensitive to how you ask the question, how you formulate examples. You need to show the model what you want and this is still a skill that is being learned and there are already people trying to use AI to do that kind of inception. Talking about the way you talked about the potential, that's a risk associated to those products. We can easily imagine that with generative AI, you could have startups building a new products that, and those products would be looking like working very, very well, potentially initially, for some examples, but potentially behind the scene, it could be very, very out of the sun, if they really, really work well at scale. And it's very important that you get a little bit of mental model around this, which is, could be a two by two matrix or three by three matrix. What I care about when I evaluate whether generative AI is, or AI in general, frankly, apt at a certain task is a combination of, does it need to be right, does the outcome of what comes out of the, does it need to be a right 100% of the time on not. Does is the result do you need to have it in real time or not. And then is this a low stakes or high stakes kind of situation. And where I'm going with this is that fundamentally as we started discussing already AI with a generative AI or not is a predictive technology and it is amazing at providing answers that are right 80% of the time 85 95% of the time but not 100% of the time. And that's a fundamental aspect of it that I think a lot of people that don't spend that much time in the space or new to the space are discovering. So long winded way of saying AI is going to be absolutely not the right technology. If you need something that needs to be right 100% of the time in a high stakes kind of situation. So you are in the ER and somebody is a minute away from dying and a judgment call needs to be made based on all that person's data and you need to, you know, a system to give you an answer that 100% of the time will tell you what you need to do right now. And it needs to be right and this is automated. AI is just nowhere near good enough to do that yet. So that's an example of a high stakes situation. Another example of a less dramatic but you know important high stakes situation that comes to mind is, you know, your calendar. And I've learned this the hard way by working with companies that were working on this problem. But you know, an AI assistant to help you schedule a meeting is actually a high stakes problem where you do need to get it 100% right 100% of the time because, you know, if the AI schedule meeting next week and ready the meeting was this week is just not cute and then, you know, pretty, pretty painful. So at the other end of the spectrum, AI is really good at all the other situations. So a situation where if you get it right 90% of the time is just amazing. So we're just talking about coding. You know, this is not real time. You don't need to get your code perfectly right at this exact second. And if the I get you 80% of the way there it's like it's a massive win. If you need to organize your pictures and you know, the AI just correctly correctly correctly. So the cluster is your photo book into, you know, the right people and you know, correctly classifies it. That's amazing. So I think that's a good matrix to figure out what AI is great at. And AI is not good for a real time sort of medical emergency type situation disaster kind of situation or even things like, you know, accounting that need to be 100% exact. You at a minimum, you can use AI for to do those things, but you absolutely need to have a human in the roof. But then at the end of the spectrum, you know, fantastic for all the other situations. To go back on that for again, taking the example of code. One of the issues that can happen is yes, of course, if it gives you the correct code 80% of the time that's already a massive win if you as a human can identify which is the 80% and which is the 20% and one risk that is very clear is if as the AI will move from 80 to 95 to 98. 8% correct humans will stop caring will stop verifying will stop proof reading why what the AI has done. And that's where you have that you have that that is so really one of the huge things is it works as long as there is oversight, but the better it works the less oversight it gets. And so yeah, Clément and I are working in the same company and so talking about human and I's next problem. I think we focus a lot at that I call on customer support. It's like dear to our heart, the quality of support. So so Clément, do you think we could automate customer support one day or part of it? It depends meaning in B2C situations where there is a very large number of customers and most of them experience the small number of very similar very repetitive issues. Yes, probably and again, the real challenge will be to tune the model so that it bails out when it's not sure that that's really the thing and that's really the one of the main issues. Right now with a generative AI is that it doesn't know when it doesn't know. But yes, if we manage to fix that it's is need to imagine that you can really solve and not just have chatbots that basically just follows rules. You can really solve maybe 80 90 maybe 95% of super tickets for B2C or more simple use case. I do not think that unfortunately for large enterprise software it will be that easy. Yeah, I think I think B2C customer support is is absolutely an area that's in the process of getting solved in a notimated way. Several companies, including one in which I'm an investor called the ADA support. I've been working on this for a long time and since just remarkable when you add LLM slot language models in the mix. It just just gives a very impressive boost. You know, I'm personally in a situation where and maybe it's because I spend time in the field, but I'm personally sick and tired of like speaking to humans and just being on the whole for customer service for you know 20 minutes listing to music and just like give me your bot and you know even even if the bot doesn't understand every single time what I what I want is just. It's such incredible. Gain in time and I think that's where we heading. I think we're going to prefer interacting with the eye than interacting with humans. And Matt do you think it has an impact on the market in terms of what kind of companies or especially tech companies will benefit from generative AI. Yeah, so I think I think there's two kinds of conversations here. There is one conversation around AI becoming part of everything. So all the existing tech companies are going to roll out AI in all their products. So you know, just the way when mobile appeared mobile became something that everybody did like everybody would start a mobile app and you know fast forward to today. It's hard to think of any company, especially consumer company that doesn't have an app of some sort. So the same thing is going to happen and it's actually already happening incredibly quickly. It's because the tech companies because nobody wants to be the company that did not roll out AI generative AI fast enough. So you seeing Microsoft very impressively just rolling out AI to like their vast suite of products, which is yesterday there was the announcement that come after announcing it a few weeks ago actually released a bunch of. Features into the suite. So you see it all over the place that just the beginning AI is going to be necessary and expected feature in every single product. The second part of the conversation is startups and you know there's a lot of discussion in VC circles and panel circles around OK. If AI is going to be everywhere on the one hand and everybody is going to be releasing their own AI version and if on the other hand you have a handful of companies, the open a eyes of the world that are the arms providers to this old gold rush or you know provider of a pixel shovels in the gold rush. Then where is the blue ocean in terms of creating new companies. My sense is that there is an immense universe of opportunities there and startups and founders again and again will find a way to build great companies and just the way in the mobile revolution. Yes, you had the everybody probably mobile in mobile apps, but you still had amazing companies that were built on the very specific capabilities of mobile. So I'm thinking of Uber and you have door dash that leverage the quintessential innovation of mobile. I think we're going to see the same thing in this phase of January of AI where people are going to build native generally, they are companies to do things that we may or may not even be able to imagine today. Yeah, because indeed there was like a lot of the investor market that was about looking for companies with a specific business model and notably subscription model in the enterprise in the past. And so to some extent it seems no longer to be about it, but do you think we're coming today where it would be a lot more about technology differentiation in many fields of deep tech climate AI. Or do you think that on the contrary because AI some AI technologies are leveling the play field. It will be back about finding the right business model leveraging technologies that are to some extent commoditized. I think it's going to be a combination and I don't necessarily think that there is a good way or bad way of going about it. There is a as part of that very new generation of generative AI companies, there's certainly a category of companies that. I think it investors circles get a little bit of bad press, which is that. You know the Jasper of the world so Jasper being a generative AI based content creator that you can use for marketing that you can use for emails that's basically sits on top of of GPT. This like that whole group of companies that are to your point very much about the business model and the go to market when really the intelligence of the system is provided by somebody else and that's a lot of discussion around okay well. That's just a thin layer. Can you really build a good company can you build the defensive company but other I Jasper is above 100 million in revenue which is very impressive and just that demonstrates that you can indeed build a company on top of somebody else's intelligence like that but you know can it be defensive all over time. My general take on this category is that I think people are being a little harsh on it. I think a lot of those companies are physically going to look like SaaS companies so you can point about that. About subscription models and then I'm going to be like any more defensive and you're less defensive all that is SaaS company and the way of SaaS company differentiates is and builds the principle of advantage is around. Work flow and collaboration and building customer base and building a community around the product so I think they will be an ex generation of SaaS companies that will be generally very power in SaaS companies and I think that's interesting. Having said that for anybody that does not do that and actually wants to build a real you know native AI company where you develop some of your own AI I think people a lot of people at least misappreciate how much of a deep tech effort that is. And how AI for all the hype and the tweets and the blog posts is still something that's really really hard and that only a tiny group of people around the world know how to do how to build to leverage. And I think this new generation of generative AI companies are going to relearn that is like it's it's hard and you probably need to spend the first two to three years of the life of a company actually building stuff building models building technology around the model. So I think we're going to be in this world of. Polyglot persistence for like a better term where you have a variety of different different business model including yes the return of a certain type of companies that are based on deep tech. And which you know is never easy but ultimately is a wonderful way of building great companies that are defensive on the monitor. But so indeed all of those tech. But indeed all of those companies are based that of working with open AI or others and actually it raised lots of questions in terms of licensing and defensibility and what you can use or not and which models are open versus not so. So claim on what's the current situation actually. Just as you describe everybody is wondering so first of all the most well known models of so the open AI models GPD 3H at GPD GPD 4 are trained on a huge corpus of text but the licensing of the text that has been used to train in the world. And so it is itself a bit unclear and there is something quite unclear about when you train a near model with a lot of text and it generates new text what is the copyright status of this new text and that's still a very undecided question. Open AI is a company that does not do open AI. So of course there are worries questions concerns about the Germany of open AI in that new world. We are already seeing competitors to open AI emerge but of course with similar rather closed business model what is extremely interesting is that there is already a lot of work a lot of interest in research in open source about replicating the deep tech behind behind open AI. There is still a significant gap the challenges around the data that is being used to train these models remains one there is also a question of cost. These models are so huge that training these models requires incredible amount of computation time which costs money it is estimated that training GPD 3GPD 4 cost several millions of dollars. So not everybody can do that and yes this costs will go down but we are not there yet so at the moment open AI and similar companies remain at the forefront so they remain gatekeepers to an extent and it will be very interesting to see how it evolves. So the situation is still in flux but so you was already comfortable still to be to be using those tools personally. Plainment do you use it to code mad do you use it to make investment decisions. I use a chat GPD very often but 90% of my usage is just to make jokes and to ask a funny questions. So tell us that your jokes are actually coming from GPD. No, not yet. I use chat GPD a bunch mostly experimenting with it as opposed to really having it part of my workflow just yet. I just try to use all these tools because it's part of the job. I use a synthasia which is an AI powered video platform where I've created my own avatar and just like use it for communication as well but you know this whole thing it's really amazing because chat GPD and about language models. I've sucked the air out of the room in terms of it so I will talk about the reality is like to chat GPD is what 4 months old now. So you know the release of it so I think I think we all trying to figure out how to build all of this into our daily workflows yet but it's. You know I certainly cannot imagine that over the next 12 months or so this is not going to be a core part of my daily workflow. I'm trying to figure out but the outcome doesn't doesn't feel like it's in question. For example things for which I actually do use chat GPD for work are naming things it's a well known trivia that in software and engineering naming things in his art and chat GPD doesn't give an answer but you can. Suggest things get in the follow leads etc and it helps again it's a tool just like I previously use the lot just says us and now I just ask questions to chat GPD and I am not using chat GPD to generate content but I am using it to summarize content because sometimes you get very long content with lots of very complex sentences. And actually the real stuff is only like one sentence two or three core ideas and for this kind of use case yes it's not it's not exactly like you said that it's not a terrible problem if it misses one thing but yeah summarizing long emails into okay this is just what you need to know yes I use that. So we'll be able to use it as part of our day to day workflow instruments if it does still exist because as we record this session there was a pose been asked I think a few days ago further enough people asking for a pose of research on giant AI models so what's your take on this. I think it's naive meaning if some people say okay let's pose or will not pose so there is no incentive for anybody to do it meaning the only way this could happen is who regulatory oversight which does not seem like some things that could happen soon. Yeah I agree I think I think it's a little bit of sort of like press and PR kind of like who plong at the same time it is asking the right question I do think that we clearly inspiration where society and the legal framework and everything is just way behind the pace of acceleration of programming. I've been working for several months and I don't think anybody is going to actually pause but there is, I mean it expresses very well discomfort that we can all feel which is like it's like every day of a new thing and there's certainly pressure from the market to do more faster. It's very interesting to me the fact that Microsoft released Bing with GPD built in it and that Google had to follow suit for me the genius of Microsoft working with OpenAI was precisely that Microsoft has a big company as a reputation to uphold and it's very careful and very deliberate in the hydrogen rolls out. And the whole beauty of working with OpenAI is like okay well we sort of the de facto backer of that outfit and yeah they can take risk but like everybody understand that it's a it's a start of. And like somehow I guess the pressure of the market was so strong and they couldn't resist and they rightly saw that it was their opportunity to maybe have a chance of like getting you know back in the ring with Google on the search front. And then Google had to react so Google which had been very careful in rolling out their AI stuff publicly and I spoke at length and published at length about the dangers of releasing AI in the world before it was fully baked. And they too had to succumb to market pressure and push at barred which you know by all accounts is just not fully baked at all and that market pressure and the fact that everybody is now rushing to push stuff that is less and less baked is carry and I do think that collectively we need to think about it and I think this urgent need for. You know industry collaboration around it which again this letter this was you know conceived through it maybe is a you know is a step towards and then you know the EU AI act and all the things that that needs to happen sooner rather later because. Without a doubt all of this is incredibly powerful technology and we need to hear how we're going to harness it as a society another world. I think to some extent something that can even more scary for real than large language model is large image models so mid journey reaction five was in the image generation model version five was released just a few years ago. And as we record this there are some protests in France is a common occurring and there has been some clashes with police and in the past few days literally just in the past two days there have been several occurrences of images of violent clashes with police that circulated on social media that generated a ton of inflammatory comments about police violence about protesters violence and this where. And it's also generated the opposite that real images were dismissed as being wrong so on images we have just entered so it has always been the case that photoshop and that image addition techniques existed but the new thing is that. Extremely good image addition is now available to everybody and not just to a few experts and that is quite a change.