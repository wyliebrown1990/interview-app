 présent d'une coup pytanie, et quand elle a été séduire. Mareilleurs amigo gezelectronic, vous Cypher Chingitlol de Marrie. Bonjour à tous. Merci d'être présent du coup du coup, pour cette conférence. comme elle vient d'être entendu. Donc, on va parler aujourd'hui de la manière d'instructures de vos plateformes de données, d'étoxification, j'irais peut-être le terme le plus important à retenir la danse, début de présentation, parce que c'est là dessus qu'on va mettre l'accent du coup j'irais au cours de cette conférence. Très rapidement et avant de passer dans les choses sérieuses il nous semble important finalement de faire un coup d'oeil dans notre visor. Pourquoi ? Parce que finalement la donnée aujourd'hui elle est partout, dans l'ensemble de vos cas d'usage, elle est dans l'ensemble de vos process métiers, j'irais qu'on doit savoir la traité correctement, c'est quelque chose qui est important et par rapport à ça il va falloir en effet que évidemment qu'on modernise, qu'on agilise finalement les écosystèmes, mais aussi qu'on regarde un petit peu derrière parce qu'il reste parfois du légatie qui est présent et sur lequel il va falloir qu'on a encore d'une importance toute particulière. Donc pour commencer je vous propose juste de faire un petit coup dans le nom rétro visor et essayer de voir ce qui s'est passé durant les dernières décennies, enfin la dernière décennie pardon, que vous avez certainement tous j'irais vécu au sein de vos organisations et qui est extrêmement importante et qui pose un petit peu le décor. Donc finalement on voit depuis 10 ans que toutes les organisations se transforment, on voulait migrer leur data warehouse existant vers des plateformes plutôt orientées vers Adouple notamment pour adhérer assez des problématiques de volumétrie de données qui étaient très importantes de manière à pouvoir adresser des nouveaux cas d'usage qui sont notamment portés dans le cadre notamment dans le jeu réglementaire sur des granéularités encore plus fines de la données. Donc la nécessité finalement d'adresser des volumes avec de la velocité. Par la suite j'irais l'ensemble de nos clients, je sais qu'ils nous sommes intervenus, on les accompagné dans leur migration vers le cloud, c'est quelque chose du coup qui est encore très présent actuellement, tout le monde n'a pas encore migré, on le verra, il y a encore des stratégies qui sont différentes aussi par rapport à ça, certains évoluent encore sur des technologies plutôt orientées en primase, d'autres vont avoir des architectures plus érides, pour y revenir un petit peu après. Mais en tout cas il y a eu une vraiment, j'irais un chantier de transformation très important qui a été réalisé du coup durant ces 10 dernières années. Chose importante finalement c'est qu'aujourd'hui on se retrouve avec des cycles de données qui sont quand même assez colossaux, on a réussi finalement à regrouper sur ces cycles toutes les données, j'irais qui proviennent de nos applications de gestion et sur lequel on va pouvoir justement commencer à développer des cas d'usage. Donc ce sont des cycles de données qui sont aujourd'hui plutôt stable, plutôt bien gouvernés, mais peut-être de façon un peu trop centralisée. On est capable donc du coup d'avoir une migration, enfin une maille de détails, pardon, relativement finissue sur ces données. Donc on a des cycles qui sont solides et sur lequel on va pouvoir commencer à construire des cas d'usages moderne. C'est vraiment l'objectif notamment de ce salon à VWDI, c'est de voir comment on peut aller plus loin avec GIRL et LLM du machine learning de la data science. Évidemment ces transformations, ça s'accompagnent aussi avec des chantiers de gouvernance parce que ce ne sont pas que des chantiers IT, c'est ça qu'il va falloir qu'on retienne, j'irais plus particulièrement. On a vu dans les organisations de nos sociétés des nouveaux postes qui se sont créés, des CDO qui sont à Paris, j'irais dans les organisations de manière à avoir de gérer une gouvernance de données qui soit transverse à l'ensemble des organisations, mieux piloter, savoir quel est l'usage de la donnée, comment on l'explore, est-ce que on est compagnant d'un point de vue GDPR des choses et donc ça ce sont des sujets finalement qu'on accompagné toutes ces transformations. Donc des chantiers IT bien évidemment, des chantiers organisationnels, surtout, et une gouvernance, j'irais assez accru sur toutes ces plateformes. Si on fait un petit peu le topo de où on s'en occupe aujourd'hui, de notre constat, ce qui est important, c'est que aujourd'hui nos clients en tous des plateformes modernes, ils ont arrêté, en effet, je dirais, le construire des plateformes avec des couches qui sont mises successivement les une derrière les autres, ils ont commencé à modulariser leurs plateformes à la rendre gérer agile de manière à pouvoir intégrer des nouveaux cas d'usage au fur et à mesure, et beaucoup plus facilement, et là évidemment, on va parler de écosystèmes autour de data IQ, notamment. C'est un des outils qui va être, j'irais assez central dans ces plateformes de données et capables de s'intégrer avec une plus ralité, j'irais de doutils et de stack techniques, on peut parler de snowflake évidemment sur la partie donnée. Donc en effet, aujourd'hui nos clients ont des plateformes qui sont modernes et sur lequel on va pouvoir capitalier. Donc, liant, on a remarqué évidemment, on pu, j'irais étendre les arts équipes avec des profils qui sont très compétents sur des sujets autour de la data science, chose qui était peut-être un petit peu plus compliqué auparavant, mais là, donc on a des plateformes qui sont robustes, on a des socles de données qui sont stable, et donc on est maintenant prêt à partir avec des personnes compétentes pour bâtir les cas d'usage demain. L'autre point, des programmes de monerdisation qui s'agilisent. Je pense que c'est ce qui a le plus important finalement dans ces transformations, c'est d'arriver à agiliser les écosystèmes. Agiliser, ça veut dire quoi ça va être justement d'être en capacité d'absorber les cas d'usage au moment où le métier va avoir besoin de les mettre en œuvre. Et finalement que l'Itin ne soit pas sort de goulot d'étranglement dans lequel finalement on va avoir des délais importants pour être en capacité d'adresser ces cas d'usage. Mais il y a quand même une chose importante. On a du coup des plateformes qui sont modernes et à côté de ça, on a peut-être encore un peu oublié, je dirais, des systèmes de légacy qui sont encore à côté de ces plateformes et sur lequel il y a encore nombreuses cas d'usage qui tournent la gérée de manière récurrente. C'est, on peut prendre un exemple, j'irais des technologies autour de ça, c'est par exemple qui sont vraiment à côté de nos plateformes, j'irais modernes de données sur lequel il y a, je sais pas si on peut qualifier tout de d'aide technique, mais en tout cas ce qui est sûr, c'est qu'il y a un panel de cas d'usage qui se trouve avec des difficultés à en sortir, ce qui fait qu'on se retrouve avec deux systèmes qui cohabitent les uns à côté des autres, avec du coup une dette technique potentiellement, des coups opérationnels et des coups financiers qui sont liés finalement à ce double âge de plateformes et du coup des coups aussi de sécurité et de gouvernance qui sont démultiplies. L'objectif, c'est qu'on mette l'accent justement sur tout ce qui va être donc ce qu'on a qualifié ici dans cette présentation de l'égassie. Le légassie, en quoi, il représente aujourd'hui un poids dans les organisations, il représente un poids tout simplement parce que c'est souvent quelque chose qui a été bâti, j'irais pendant plusieurs années, et sur lequel on a un certain nombre de maîtrises, le maîtrise, parce que c'est un patrimoine qui est souvent assez peu documenté, qui a été construit notamment principalement avec du chat do itile notamment, et sur lequel on a vraiment deux maîtrises. Aujourd'hui, si on veut faire évoluer, je dirais, ce légassie, ça nécessite d'avoir des compétences aussi assez accru sur les technologies qui sont maîtrises. Pour un coup, on peut parler ici de ça, qui a été vraiment quelque chose qui a été très moteur, j'irais dans un certain nombre d'années, mais aujourd'hui qui est plutôt en perte de vitesse, on a des recru qui accompagnons aux équipes qui ont de plus d'emballes à prendre la main sur ces écosystèmes et qui sont plus orientés vers des nouvelles technologies autour de pitons, autour de air, autour de sparks, bien évidemment, et avec du coup des compétences peut-être moins importantes sur ces légassies. Donc, il y a vraiment une difficulté, j'irais sur ces systèmes qui va falloir, sur lesquels il va falloir qu'on arrive à reprendre la main. Donc, évidemment, ce sont des chantiers qui sont très importants à ces colossaux. On a souvent peur d'y aller, néanmoins, il faut savoir franchir le pas. C'est un vrai changement de paradigme, c'est-à-dire qu'au par avant où on avait, j'irais une frontière assez importante entre les métiers, la IP, la IT, là, il va falloir vraiment qu'on arrive à agiliser les écosystèmes et donc à faire en sorte que le partenariat métier et IT soit vraiment mis en avant. C'est ce qui va faire finalement la réussite de toute cette transformation et de toute la modernisation de tous les écosystèmes à dos, de tous les écosystèmes d'attapeurs. L'idée, c'est évidemment de pas produire les erreurs du passé. On va éviter avec cette agilisation, avec justement cette collaboration entre les métiers et la IT, on va favoriser, j'irais, la non-reproduction des erreurs, notamment le Shadow IT. Le Shadow IT, qu'on veut essayer de éviter au maximum, il n'est pas de l'euro-produire, faut qu'on arrive à capitaliser sur les erreurs, qu'on a fait ou parable. L'idée évidemment de cette agilisation, c'est d'arriver à délivrer toujours plus, j'irais des qualités, des produits d'attape, de qualité, avec un délivre relativement important. Et enfin, c'est aussi une opportunité, ça va être de apporter une gouvernance qui soit différente. Quand on était sur des plateformes à d'où, que sont les gouvernances très centralisées de la donnée, finalement. La l'idée, c'est aussi d'adopter peut-être des méthodologies autour du data mesh, qui vont nous permettre, finalement, de décentraliser cette gouvernance auprès d'acteurs métiers qui vont être responsables de la donnée, et sur qui on va pouvoir s'appuyer pour assurer une meilleure gouvernance sur toutes les données. C'est un des points importants. Mais pour faire tout ça, évidemment, comme je disais, on a un legacy, et l'idée, dans le cadre de cette présentation, c'est qu'on fasse un peu l'accent sur ce legacy. Comment on va pouvoir finalement le réinventer, et ce qu'il faut le migrer, que faisons-nous avec, et c'est là toute la question. On va vous présenter un certain nombre à un condron, c'est de nos retours d'expérience, finalement, de projets qu'on a pu réaliser chez nos clients. Et je vais donc laisser la main à Stéphane, qui va vous présenter tout ça. Bonjour à toutes et bonjour à toutes. J'espère que vous vous m'entendez bien. Le point de départ sur le legacy, c'est dans un monde idéal, ça serait de partir de la faille blanche, de se dire on sait exactement où on veut aller, et on déroule. Dans la vraie vie, c'est loin d'être le cas, et comme il a dit à l'exembre, on a un nombre important de patrimoine applicatif qui existe, et l'idée c'est pas de faire RZ sur tout ce qui a été fait, mais de voir dans quelle mesure on va pouvoir capitaliser sur tout ce qui a été construit depuis des années. Déjà, le premier chose de nos retours, c'est que en effet, on voit qu'il y a quand même des erreurs à éviter, c'est-à-dire que si on reprenait l'exembre qui a été évoqué tout à l'heure sur un patrimoine existant, c'est de se dire, ah c'est trop gros, et donc on va attendre et on recule, on recule, on recule, et puis finalement, on n'aborde jamais le problème. Donc vraiment, essayez de prendre conscience que il faut à un moment commencer. À l'opposer, c'est de se dire, bon, c'est va être facile, on y va, et puis on se met une deadline, et puis toute façon, ça sera migré. Donc là, on a vu un nombre assez important de programmes où on se dit, bon bah, dans un an, tout l'existent doit être migré. Donc ça, au bout du compte, une fois que c'est lancé, les problèmes apparaissent et on voit que rien n'est jamais simple. D'autres points aussi, c'est de se dire, bon, on a un parc important, on a beaucoup de programmes, et donc on va commencer par le plus dur. Sauf que, en général, commencer par le plus dur, c'est là où on va passer le plus d'énergie, et comme on n'aura pas commencé par quelque chose de plus accessible, très rapidement, ça ne sera pas forcément représentatif, et ça peut avoir aussi un impact sur finalement le déroulé d'une migration, d'une modernisation. L'autre type d'erreur, c'est aussi de vouloir tout migrer à même temps. On se dit, on va assez facile, on fait X-Stream, et on lance ça en parallèle, et donc là, ça va bien vite l'anarchie, et on passe plus de temps sur la coordination, finalement, que de se poser les bonnes questions et de savoir de comment le migrer correctement. Une autre erreur aussi, c'est de se dire, bon, on a un parc existant, on va pas se poser de questions, on va faire simple, on le migre un pour un. Donc ça, ça peut paraître une bonne idée au départ, sauf que finalement, la dette technique que l'on avait potentiellement avec des technologies, on attendance à la retranscrire. Donc l'idée, c'est qu'il y a quand même des programmes qui peuvent être pertinents de migrer un pour un, mais c'est aussi d'en profiter de ces étapes, de modernisation, pour se poser la question de, est-ce que tout doit être migré et comment. Et enfin, le dernier erreur, c'est aussi un peu dans l'air du temps, c'est de se dire que la magie existe. Donc là, on va faire un pronte chat de GPT, et on va nous dire, on va assez facile, voici la procédura suite. Aujourd'hui, enfin, il faut sortir de cette hypothèse, et ça va pas être forcément très pragmatique en termes de mise en œuvre. Donc comment on appréhendait ce cascet ? Donc là, ce que l'on propose, c'est ce que l'on voit, c'est qu'il y a plusieurs étapes, c'est de procéder par étape. La première est en, finalement, de remetriser son patrimoine d'attaque. Remetriser, ça veut dire quoi ? Ça veut dire que par rapport à un manque de documentation, un manque de compréhension, et finalement de subir un existant, l'idée, c'est de pouvoir reprendre la main et recartographier de manière la plus pragmatique. Donc ça veut dire s'appuyer sur des accélérateurs, et s'appuyer sur la connaissance des personnes qui sont là. Et donc l'idée, ça va être de pouvoir accompagner les clients sur de la représentation graphique, puisque, un de nos convictions, c'est de se dire finalement, il n'y a rien que mieux que de voir les chaînes de traitement et de manière visuelle, de pouvoir se rendre compte de la complexité et de la topologie des traitements. Les étapes suivantes, c'est qu'une fois qu'on a cette cartographie, on va pouvoir commencer à travailler sur ce qui est le plus important et identifier une étape en disant, est-ce qu'il n'est pas pertinent de mettre de côté certains bout de programme, puisque on a constaté qu'ils n'étaient soit pas utilisés. Donc ça, on a des cas où des chaînes de traitement tournent pour générer des data sets qui, infiné ne seront pas utilisés, donc c'est du temps de calcul en plus. C'est du temps perdu, c'est du temps machine. Et donc l'idée là, c'est de se poser la question sur cette cartographie, qu'est-ce qu'il est important de migrer et comment on va le faire. Et donc là, ça est sur le point de droit, c'est de travailler vraiment sur une stratégie de migration et d'identifier de manière très pragmatique l'ensemble des contraintes organisationnels, technique et de temps et de l'objectif, c'est de définir des stratégies réalistes, de migration. Tout ça, ça va s'accompagner par l'accompagnement et donc de l'on-boarding de l'ensemble des acteurs et donc avec tout un pan de formation, justement et de conduit du changement de l'ensemble des acteurs. Et une fois qu'on a finalement la cartographie, qu'on a définit notre roadmap, qu'on sait qui va intervenir où et comment, après on peut passer sur un mode accéléré. Et d'iterration, en se disant, on a l'approche des petits pas, on commence par un premier lot, on capitalise dessus et tout ce qu'on va découvrir au firmesur. L'idée c'est que les points qu'on va découvrir, les points durs qu'on va découvrir et qu'on va résoudre, l'idée c'est qu'on les résolve une fois pour toutes et que si il y a une autre d'autres programmes arrivent et qui sont de la même, qui sont similaires, qu'on puisse finalement réutiliser de manière très opérationnelle, ce qui a déjà fonctionné. Donc là l'objectif, ça va être de pouvoir, donc là ça me exemple sur qui est présenté, de correspondance entre un programme, donc là c'est du script de sas en entrée, qui a été migré en automatique sur du datayku, on voit les correspondances, on voit à quoi correspond le bout de programme dans la datayku et la source. Et donc l'idée c'est d'avoir des accélérateurs et d'avoir une approche vraiment pragmatique d'accompagnement et d'un boarding de l'ensemble des acteurs. Est-ce que là je pense que... Donc en effet tous ces chansiers qu'on vient d'évoquer, de mise en place de nouvelles plateformes, de gérer de migration, de modernisation de ces legacies, c'est aussi vraiment des opportunités. Pourquoi ? Parce que si on a construit ces nouvelles plateformes de données, l'idée c'est d'entirer le maximum de R.O.I. Et finalement, en migrant, je gérerai ce soleil des galaxies sur ces nouvelles plateformes, c'est un moyen d'être de tirer encore plus de R.O.I sur ces nouvelles plateformes. Comme le disais Stefan, même si l'idée c'est pas de faire du impourent, puisque ça n'a pas forcément de sens, c'est l'idée c'est pas de refaire une dette technique à partir d'une dette technique. Le R.O.I est important et faut qu'on arrive du coup à migrer intelligemment, gérer ces programmes sur les plateformes. Le autre point, je l'ai évoqué du coup au début de cette conférence, c'est que on a de de plateformes qui cohabitent. Donc le logiciel avec les nouvelles plateformes, on a de la duplication de données, chose qu'on souhaite éviter, notamment pour assurer une meilleure gouvernance, des efforts de sécurité et de gouvernance, donc du coup qui sont vraiment très importants. Aujourd'hui, il y a des efforts qui sont mis à la fois sur le maintien en condition opérationnelle de ces plateformes. On a du mal à qualifier l'usage qui est fait de la donner sur ces dégâts-ci. L'idée c'est qu'on arrive à vraiment reprendre la main sur ces périmètres et donc ces chantiers de modernisation sont vraiment des vecteurs de progression. Un autre point, c'est que la modernisation des assis, c'est aussi de bâtir des assis qui sont évolutifs. Le Vois, le LLM est apparu, j'irai maintenant, il y a quelques mois, qui est apparu très vite. Aujourd'hui, on en parle, j'irai un petit peu partout. Il n'y a pas une semaine sans que finalement il y ait un nouveau moteur qui sort sur les aspects LLM. Si on veut intégrer rapidement, finalement, ces nouvelles technologies pour bâtir nos cas d'usage futures dessus, il est important de bâtir du coup des assis qui soient évolutifs, agile. Et ça, ça ne se fait qu'au travers d'une collaboration parfaite entre les IT et les métiers. C'est également l'occasion évidemment de rationaliser le plateform. Ça va soit, j'irai que d'avoir deux plateformes à maintenir en parallèle, c'est du coup opérationnel. C'est évidemment du coup financier. On va parler en effet de coup financier, puisqu'il y a derrière du licensing qui est géré évidemment au travers de ces plateformes. Donc, il y a vraiment un enjeu fort géré à rationaliser. Et enfin, dernier point, sur tout ce qui est qu'à d'usage, on a aujourd'hui une fois qu'on a cartographié des quats d'usage, on a certains sur lequel on est certain qu'il va falloir les remettre au goût du jour. Pourquoi ? Parce qu'on les avait plutôt les 7 côtés pendant un temps, peut-être qu'on en avait perdu la maîtrise. L'idée, c'est justement qu'on arrive à reprendre la main dessus à leur mettre au goût du jour, en intégrant peut-être des nouvelles fiatures et de pouvoir capitaiser encore une fois sur ces plateformes. En un mot ou plutôt en trois mots, ça serait plutôt changer de paradigme en effet et à adopter cette démarche de modernisation, pour être le plus efficace à l'adoption des cas d'usage futurs.