 talking about real world applications of Gen AI and Philip, you've been I think two years at Deloitte. Yes. Yeah, so we're going to be excited to hear it today. Thank you very much. Well, thank you for the introduction and I'm happy that my real title of the presentation actually is a reference to the story that you told in the beginning. So I want to talk about shifting gears into enterprise-grade Genitive AI. So we've heard a little bit about risks and limitations, which I will also get into, but really try to focus on what we see in different enterprises that Genitive AI can do and where Genitive AI can really make a difference. But before we get started into that, we had a little bit of an introduction into what is artificial intelligence, where does it come from? As Anastasia said, it started in the, yeah, 50s. Among starters, with John McCartney, defining what is artificial intelligence and then going further in the 80s with machine learning, where we kind of figured out that not computers cannot just learn or cannot be steered through rules, but can actually also learn. So we started giving computers, original algorithms, examples of, for example, pictures and labels and machines started to learn patterns and were able to classify certain things. This went further with the technology, or as technology increases with the availability of GPUs. We were able to extend these neural networks and create what is called deep learning, and then way longer ago, like we already heard than a year ago, this whole topic of Genitive AI emerged. And of course, one year ago, everybody started talking about it. Finally enough, and this graph is taken from a survey that was done by Deloitte, one of the biggest global surveys around Genitive AI, where executive leaders are asked a bunch of questions about AI, and here the graph shows how important do executives think AI is for the success of an organization. As you can see here, on a global average, 94% of these 2500 executives were saying that AI is important. This is a really big number, and I think a very positive development to everyone in this room. If you look at the graph more carefully, you see Germany is 87%, while that may sound like a really big number, it's almost 9 out of 10. If you look at the ranking of the countries, Germany is actually at the last spot. So this is just a subset. There were over 15 countries surveyed, and Germany is at the last spot. This becomes a little more scary in the next quote. This is a quote in a study made by Bitcom just a month ago, where they asked how generative AI is already, or what enterprises plan to use generative AI. In this study, it was found that 2% of enterprises in Germany are currently using generative AI. Well, this is fairly new technology, so things that are production-ready are not that white spread yet, but only 13% of organizations actually have a plan on using generative AI in their business. So I'm happy to be talking to a crowd today, where I hope you are in these 15%. If you're not, maybe some of these numbers can convince you, we already heard a little bit about all the productivity growth that is expected from generative AI, depending on the studies, these numbers, of course, differ. But I just want to talk about the first one that 80% of jobs will be impacted by generative AI. Impact that you're in the sense not replaced, but impacted. That means that 80% of your jobs will in some way or another see and feel the impact of generative AI. And this is relevant to enterprises, not because people have started playing around with technologies that I mentioned on the top of the iceberg here, like OpenA-SChat, GBT, or Google Spard, or even creating pictures with my journey. But enterprises really need to focus on everything that is below the iceberg. What are the business cases? What are legal implications, or risks and regulatory implications, and how to create a scalable and robust framework to really implement these solutions? Before we get into that, a quick recap on what generative AI can do. We usually talk a lot about text. The text has been the main thing in public media over the past year, but these foundation models, the technology that generative AI is built upon, can do much more. So you can see here in text, I think we're all familiar with, but these models are getting better and better at also writing code. So we see a lot of companies and enterprises trying to incorporate these models to not just write code, but to translate requirements into user stories and then break it down and give these models simple and small user stories to then code. And it works fairly well. This, of course, goes on to creating images, creating videos. There are a couple of very scary examples about audio, there are systems that are not available to the public that can recreate your voice with a three-second sample of your voice, such that your parents will not be able to distinguish if it was machine created or not. So of course, this is scary, but the technology can do a lot. And the last case, I'm not sure how many of you are familiar with this, there are specialized models. In some cases, for some enterprises, it makes sense to train specialized models that generate specific outcomes. For example, in this case, a model was trained to generate protein folding in 3D space. So instead of having to go through numerous experimental concepts to arrive at how proteins fold, a generative AI could generate these proteins, how they folded in 3D space. The limitations, now even though these systems have so many applications and a lot of, like, they are still limitations to the systems that we heard about. I want to touch on a few that you already mentioned before, but these are the limitations that are inherent to the foundation models. For simplicity, I will talk about LLMs here. And the LLMs are trained. They are trained. They are large models trained on a lot of data requiring a lot of GPUs and requiring a lot of time, meaning that there is a cut-off date for a model. The model has been trained on a certain data set and is not retrained very frequently, meaning that the data and the, quote unquote, knowledge that is inherent in these models or the context has a cut-off date and does not have access to the newest information. Because this can, as we heard in our first talk, be some hosts are commented by using techniques like retrieval augmented generation where a database is connected to the large language model, then making it able for the LLMs to access more recent or actually accurate data. We heard about the term hallucinations. The term when these models generate hallucinated facts, so bluntly just wrong statements. Of course, it's being worked on that this will happen less and less frequently, but in the end, these large language models produce text based on probabilities of what they have read. This will never be 100% correct. In the same similar, these models are not capable of human-like reasoning. This is especially important when we consider customer-facing applications. Even though these models have become with time better and better at reasoning, they are not in any way comparable to what we humans are capable of. This is a very interesting thing, what the quote that Anastasia also mentioned from Picasso, Chatshipi, for example, is very bad at asking questions. It will give you answers for whatever you ask, but actually thinking about if your question makes sense in the first place or not, it's not built into these systems. This is where human or our reasoning comes in. Another point I want to mention is these models can be biased. Of course, they are trained on a big data from the internet, common crawl, or whatever data sets are used in training these models. Those data are inherently biased because they were written by or made by humans, which we all are in some extent or another subconsciously or not biased. In some applications, this might not make too much of a difference, but it's always important to consider that these models can have a bias and that this should always be taken into account. Now, of course, these are limitations that are limiting the technology, but there's also challenges that the business has to consider. There's constant benefit questions, if the bigger and bigger the models get, the more compute they need, the more expensive they get. Or we've seen in our first talk how many vendors are in this space and how many vendors will keep going into this space or enterprises need to consider which vendors to partner with. Deploying these solutions, we also heard about this already, on premise, deploying in the cloud, or which pipelines where this deployment needs to happen. And of course, the question everybody is asking the legal implications, who owns the output, like all these questions that enterprises need to consider. And with usually with new technologies, there is a large phase of just thinking about adoption and starting small, but as we've heard, and then, we've seen a lot of different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different, very different. Very different, very different. Very different. So have fun, have fun, have fun, have fun. The way that I've said to my partner now say... content on specific customer segments or for specific purposes. Before Generative VI, for example, writing product descriptions was a very tedious task writing a product descriptions that fit to the vision and the style of the company that fits the product, now all of a sudden feeding a generative system with thousands of product descriptions in a certain style, it can generate very similar product descriptions for a lot of different customer segments that was just not feasible before. And lastly, the capability play, generative VI can generate new insights. All of a sudden we have this technology which is able to read large amounts of texts, summarize them, do this quicker than any human can, and thereby really generate insights not just for developers or people who already work with data on a daily basis, but even enable the businesses and management to access data using generative VI solutions. And this brings me to my next slide saying, in order to deploy generative VI solutions, it takes a village. It means it makes sense to include everyone to really stand up across disciplinary team in your enterprise in order to really leverage the benefits of generative VI. In this case, it doesn't not only include the business side and IT, but actually also include legal risk and regulatory because this space will change and will be extremely difficult to navigate, but also things like human capital, the workforce will change the way that not just the workforce pyramid, but also the way our everyday lives what skills will be important for the future, what skills will be important for your enterprise when generative VI is really implemented into everyday life. And in order to lastly give you a little bit of an insight into what is important when thinking about use cases, let me quickly introduce this framework. Of course, things like impact and feasibility are still relevant to use cases, but as we've heard, generative VI, one really important thing with these solutions and with the output is to validate the output. The machine cannot at this point validate whether or not the output that was generated is true or false. Let me give you a quick example. If I were to ask you to invent a joke, for some of you that might be easy, for some of you not, but validating whether the joke that you just invented was good or not is fairly easy, either the people laugh or not. And in this case, it really, on generative VI use cases, it makes sense to think about who will do the validation and how fast will the validation go. If a person who doesn't really know how to write code, all of a sudden writes code with these systems, the validation process will be extremely hard because the person doesn't know how to write code. On the other hand, if a developer uses these systems to aid, then the validation will be much, much simpler. And with this, thank you very much. There are a couple of publications from Deloitte amongst others, a selection of generative VI use cases and since that's where we get the most questions from other legal implications of generative VI. So thank you very much.